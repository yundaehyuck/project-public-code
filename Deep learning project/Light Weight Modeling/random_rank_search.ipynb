{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "random_rank_search.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "598e107d-d7a0-46c7-bd50-6befa9f32034"
      },
      "source": [
        "## Load library"
      ],
      "id": "598e107d-d7a0-46c7-bd50-6befa9f32034"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d64dacef-493a-4405-8497-55a160ddee62"
      },
      "source": [
        "#python\n",
        "\n",
        "import json\n",
        "import copy\n",
        "import random\n",
        "import yaml\n",
        "\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict, Tuple, Union, List\n",
        "\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm,notebook\n",
        "\n",
        "#automl optuna\n",
        "import optuna\n",
        "\n",
        "#sklearn\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#numpy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#pytorch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "#baseline\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('/opt/ml/code/src/'))))\n",
        "\n",
        "import src\n",
        "\n",
        "from src.dataloader import create_dataloader\n",
        "from src.loss import CustomCriterion\n",
        "from src.model import Model\n",
        "from src.trainer import TorchTrainer\n",
        "from src.utils.common import get_label_counts, read_yaml\n",
        "from src.utils.macs import calc_macs\n",
        "from src.utils.torch_utils import check_runtime, model_info, save_model\n",
        "from src.augmentation.policies import simple_augment_test\n",
        "from src.utils.inference_utils import run_model\n",
        "\n",
        "\n",
        "from train import train\n",
        "\n",
        "#musco\n",
        "\n",
        "from musco.pytorch import CompressorVBMF, CompressorPR, CompressorManual\n",
        "from flopco import FlopCo\n",
        "from musco.pytorch.compressor.rank_selection.estimator import estimate_rank_for_compression_rate, estimate_vbmf_ranks\n",
        "\n"
      ],
      "id": "d64dacef-493a-4405-8497-55a160ddee62",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df4509cd-3490-49a7-9d12-5335a99f3855"
      },
      "source": [
        "## hyperparameter"
      ],
      "id": "df4509cd-3490-49a7-9d12-5335a99f3855"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1653306a-8bd7-427f-b550-962b98e86b37"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "id": "1653306a-8bd7-427f-b550-962b98e86b37",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5df0adb-66dc-4ca2-ae61-37c29310e5ed"
      },
      "source": [
        "## fixed seed"
      ],
      "id": "c5df0adb-66dc-4ca2-ae61-37c29310e5ed"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "339ad3a5-c28a-40ed-a193-652cd06df100"
      },
      "source": [
        "#torch seed\n",
        "torch.manual_seed(30)\n",
        "torch.cuda.manual_seed(30)\n",
        "\n",
        "#numpy seed\n",
        "np.random.seed(30)\n",
        "\n",
        "#python seed\n",
        "random.seed(30)"
      ],
      "id": "339ad3a5-c28a-40ed-a193-652cd06df100",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "838ddd6f-da69-4838-9978-b9fceaf6ce13"
      },
      "source": [
        "## load base model"
      ],
      "id": "838ddd6f-da69-4838-9978-b9fceaf6ce13"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e0e8699-388b-4c54-a74e-244ac2eb4003"
      },
      "source": [
        "model_config = read_yaml(cfg=\"exp/0.5177_100epoch_1120/model.yml\")\n",
        "data_config = read_yaml(cfg=\"exp/0.5177_100epoch_1120/data.yml\")\n",
        "\n",
        "model_config = read_yaml(cfg=model_config)\n",
        "data_config = read_yaml(cfg=data_config)"
      ],
      "id": "5e0e8699-388b-4c54-a74e-244ac2eb4003",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ad5005b-6e2c-41be-9ebb-6ec0628f7d49",
        "outputId": "14803e6f-db3d-4e42-ef40-7d032b95ceaa"
      },
      "source": [
        "model_instance = Model(model_config,verbose=True)"
      ],
      "id": "4ad5005b-6e2c-41be-9ebb-6ec0628f7d49",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "idx |   n |     params |          module |            arguments |   in_channel |   out_channel\n",
            "----------------------------------------------------------------------------------------------\n",
            "  0 |   3 |        816 |          DWConv | [16, 3, 2, None, 'ReLU'] |            3           16\n",
            "  1 |   1 |      2,016 | InvertedResidualv2 |           [32, 2, 2] |           16           32\n",
            "  2 |   4 |      2,288 | InvertedResidualv2 |           [16, 1, 2] |           32           16\n",
            "  3 |   5 |      7,360 | InvertedResidualv2 |           [16, 2, 2] |           16           16\n",
            "  4 |   2 |    240,656 | InvertedResidualv3 | [5, 3.5, 128, 1, 1, 2] |           16          128\n",
            "  5 |   1 |     83,200 |            Conv |          [640, 1, 1] |          128          640\n",
            "  6 |   1 |          0 |   GlobalAvgPool |                   [] |          640          640\n",
            "  7 |   1 |      5,778 |       FixedConv | [9, 1, 1, None, 1, None] |          640            9\n",
            "Model Summary: 161 layers, 342,114 parameters, 342,114 gradients\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6741384-7f1b-40ad-b605-35199a077bbb"
      },
      "source": [
        "model_path = 'exp/0.5177_100epoch_1120/best.pt'\n",
        "\n",
        "if os.path.isfile(model_path):\n",
        "    model_instance.model.load_state_dict(torch.load(model_path, map_location=device))"
      ],
      "id": "d6741384-7f1b-40ad-b605-35199a077bbb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b45b3a0b-feac-4ff2-9265-3c801fc976c9",
        "outputId": "abc9d66d-4c76-4f4d-84ce-652cd895c89e"
      },
      "source": [
        "#calculate original_macs\n",
        "\n",
        "original_macs = calc_macs(model_instance.model, (3, data_config[\"IMG_SIZE\"], data_config[\"IMG_SIZE\"]))\n",
        "print(f\"macs: {original_macs}\")"
      ],
      "id": "b45b3a0b-feac-4ff2-9265-3c801fc976c9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "macs: 11242418.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "843eb322-97e1-4a7c-aad9-a74b52947f2a"
      },
      "source": [
        "## create register_buffer"
      ],
      "id": "843eb322-97e1-4a7c-aad9-a74b52947f2a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5fb9de1-841d-4e8f-bc68-a9d3b5432da7"
      },
      "source": [
        "for name, param in model_instance.model.named_modules():\n",
        "    if isinstance(param, nn.Conv2d):\n",
        "        param.register_buffer('rank', torch.tensor([0.5,0.5]))# rank in, out   "
      ],
      "id": "f5fb9de1-841d-4e8f-bc68-a9d3b5432da7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c9c40d6-cfc0-4fe2-96b4-c418b981f7e3"
      },
      "source": [
        "## calculate model statistic"
      ],
      "id": "5c9c40d6-cfc0-4fe2-96b4-c418b981f7e3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65cbc009-bab6-4ac3-853e-76416012786e"
      },
      "source": [
        "model_instance.model = model_instance.model.to(device)\n",
        "model_instance.model = model_instance.model.eval()\n",
        "model_stats = FlopCo(model_instance.model, img_size=(1,3,data_config['IMG_SIZE'],data_config['IMG_SIZE']), device = device)"
      ],
      "id": "65cbc009-bab6-4ac3-853e-76416012786e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "794db943-2d0c-4be8-81b7-583fdb0d3aa1"
      },
      "source": [
        "model_stats.total_flops,  model_stats.relative_flops"
      ],
      "id": "794db943-2d0c-4be8-81b7-583fdb0d3aa1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8af5219b-cd89-47f0-a2d6-f7daf787a7d0"
      },
      "source": [
        "## find model conv layer for compression"
      ],
      "id": "8af5219b-cd89-47f0-a2d6-f7daf787a7d0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "a397e5c0-6fe7-4d97-a301-1faf7f6fc77c"
      },
      "source": [
        "all_layer = [k for k in model_stats.flops.keys()]\n",
        "all_layer"
      ],
      "id": "a397e5c0-6fe7-4d97-a301-1faf7f6fc77c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "1d948a7c-a649-4db8-8c7b-4847e6c3ce06"
      },
      "source": [
        "lnames_to_compress = [k for k in model_stats.flops.keys() if\\\n",
        "                      model_stats.ltypes[k]['type'] == nn.Conv2d and\\\n",
        "                      model_stats.ltypes[k]['groups'] == 1\n",
        "                     ]\n",
        "lnames_to_compress"
      ],
      "id": "1d948a7c-a649-4db8-8c7b-4847e6c3ce06",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2784ce07-ee51-40c6-9fcb-fb8a09fd3f3d"
      },
      "source": [
        "## define compression function"
      ],
      "id": "2784ce07-ee51-40c6-9fcb-fb8a09fd3f3d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "2d01f99f-fe16-4f68-ad37-7a3021f46732"
      },
      "source": [
        "def compression(lnames_to_compress, device, model_instance):\n",
        "    for lname in lnames_to_compress:\n",
        "\n",
        "        ranks =  {k:None for k in all_layer}\n",
        "\n",
        "        for name, param in model_instance.model.named_modules():\n",
        "            if lname == name:\n",
        "                if param.groups == 1:\n",
        "                    tensor_rank = getattr(param, \"rank\")\n",
        "                    rank = [int(r * param.weight.shape[i]) for i, r in enumerate(tensor_rank)]\n",
        "                    ranks[lname] = [max(r, 2) for r in rank]\n",
        "                    break\n",
        "\n",
        "        if ranks[lname] == None:\n",
        "            continue\n",
        "\n",
        "        compressor = CompressorManual(model_instance.model, model_stats,ranks = ranks, ft_every = 1, conv2d_nn_decomposition='tucker2', nglobal_compress_iters = 1)\n",
        "\n",
        "        compressor.decompositions = {k:'tucker2' for k in compressor.decompositions.keys()}\n",
        "\n",
        "        while not compressor.done:\n",
        "            #print(\"\\n Compress\")\n",
        "            compressor.compression_step()\n",
        "\n",
        "            #print(\"\\n Calibrate\")\n",
        "            #compressor.model = calibrate(compressor.compressed_model, device, train_dl,freeze_lnames = lnames_to_compress[:idx])\n",
        "\n",
        "            compressor.compressed_model = compressor.compressed_model.to(device)\n",
        "\n",
        "            #macs = calc_macs(compressor.compressed_model, (3, data_config[\"IMG_SIZE\"], data_config[\"IMG_SIZE\"]))\n",
        "            #print(f\"macs: {macs}\")\n",
        "\n",
        "            #print(\"\\n Test\")\n",
        "            #test(compressor.compressed_model, device, val_dl)\n",
        "\n",
        "            #print('\\n Fine-tune')\n",
        "\n",
        "        model_instance.model = compressor.compressed_model\n",
        "    \n",
        "    return model_instance.model"
      ],
      "id": "2d01f99f-fe16-4f68-ad37-7a3021f46732",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8964f25-3229-4818-91f7-c0c29faf7638"
      },
      "source": [
        "def train(model_instance, model_path, optimizer, scheduler, criterion, scaler, train_dl, val_dl, device):\n",
        "    \n",
        "    n_epoch = 30\n",
        "\n",
        "    best_test_acc = -1.0\n",
        "    best_test_f1 = -1.0\n",
        "\n",
        "    num_classes = 9\n",
        "\n",
        "    label_list = [i for i in range(num_classes)]\n",
        "\n",
        "    for epoch in range(n_epoch):\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "        preds, gt = [], []\n",
        "        pbar = notebook.tqdm(enumerate(train_dl), total=len(train_dl))\n",
        "        model_instance.train()\n",
        "        for batch, (data, labels) in pbar:\n",
        "\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "            if scaler:\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    outputs = model_instance(data)\n",
        "            else:\n",
        "                outputs = model_instance(data)\n",
        "            outputs = torch.squeeze(outputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if scaler:\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            _, pred = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (pred == labels).sum().item()\n",
        "            preds += pred.to(\"cpu\").tolist()\n",
        "            gt += labels.to(\"cpu\").tolist()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            pbar.update()\n",
        "            pbar.set_description(\n",
        "                f\"Train: [{epoch + 1:03d}] \"\n",
        "                f\"Loss: {(running_loss / (batch + 1)):.3f}, \"\n",
        "                f\"Acc: {(correct / total) * 100:.2f}% \"\n",
        "                f\"F1(macro): {f1_score(y_true=gt, y_pred=preds, labels=label_list, average='macro', zero_division=0):.2f}\"\n",
        "            )\n",
        "        pbar.close()\n",
        "\n",
        "        _, test_f1, test_acc = test(\n",
        "            model=model_instance, test_dataloader=val_dl\n",
        "        )\n",
        "        if best_test_f1 > test_f1:\n",
        "            continue\n",
        "        best_test_acc = test_acc\n",
        "        best_test_f1 = test_f1\n",
        "        print(f\"Model saved. Current best test f1: {best_test_f1:.3f}\")\n",
        "        save_model(\n",
        "            model=model_instance,\n",
        "            path=model_path,\n",
        "            data=data,\n",
        "            device=device,\n",
        "        )\n",
        "    \n",
        "    return best_test_acc,best_test_f1"
      ],
      "id": "a8964f25-3229-4818-91f7-c0c29faf7638",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63d77a4b-23fd-4b8d-88b4-fd8d7f6314dd"
      },
      "source": [
        "@torch.no_grad()\n",
        "def test(model,test_dataloader):\n",
        "    \"\"\"Test model.\n",
        "\n",
        "    Args:\n",
        "        test_dataloader: test data loader module which is a iterator that returns (data, labels)\n",
        "\n",
        "    Returns:\n",
        "        loss, f1, accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    #n_batch = _get_n_batch_from_dataloader(test_dataloader)\n",
        "\n",
        "    running_loss = 0.0\n",
        "    preds = []\n",
        "    gt = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    num_classes = 9\n",
        "    label_list = [i for i in range(num_classes)]\n",
        "\n",
        "    pbar = notebook.tqdm(enumerate(test_dataloader), total=len(test_dataloader))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    for batch, (data, labels) in pbar:\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "        if scaler:\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(data)\n",
        "        else:\n",
        "            outputs = model(data)\n",
        "        outputs = torch.squeeze(outputs)\n",
        "        running_loss += criterion(outputs, labels).item()\n",
        "\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "\n",
        "        preds += pred.to(\"cpu\").tolist()\n",
        "        gt += labels.to(\"cpu\").tolist()\n",
        "        pbar.update()\n",
        "        pbar.set_description(\n",
        "            f\" Val: {'':5} Loss: {(running_loss / (batch + 1)):.3f}, \"\n",
        "            f\"Acc: {(correct / total) * 100:.2f}% \"\n",
        "            f\"F1(macro): {f1_score(y_true=gt, y_pred=preds, labels=label_list, average='macro', zero_division=0):.2f}\"\n",
        "        )\n",
        "    loss = running_loss / len(test_dataloader)\n",
        "    accuracy = correct / total\n",
        "    f1 = f1_score(\n",
        "        y_true=gt, y_pred=preds, labels=label_list, average=\"macro\", zero_division=0\n",
        "    )\n",
        "    \n",
        "    return loss, f1, accuracy"
      ],
      "id": "63d77a4b-23fd-4b8d-88b4-fd8d7f6314dd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab277981-bcd1-47e8-8a01-ed76126e7d59"
      },
      "source": [
        "## define objective function"
      ],
      "id": "ab277981-bcd1-47e8-8a01-ed76126e7d59"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4efbd7ed-9f1d-4be4-b510-bfe903771aa0"
      },
      "source": [
        "def objective_one(trial, device, model_config, data_config, model_path):\n",
        "    \n",
        "    #create model_instance\n",
        "    \n",
        "    model_instance = Model(model_config,verbose=False)\n",
        "    \n",
        "    #filled best pretrained weight\n",
        "    \n",
        "    if os.path.isfile(model_path):\n",
        "        model_instance.model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    \n",
        "    #hyperparameter\n",
        "    \n",
        "    rank = {}\n",
        "    \n",
        "    for name, param in model_instance.model.named_modules():\n",
        "        if isinstance(param, nn.Conv2d):\n",
        "            rank_one = trial.suggest_uniform(name+'_one',0.0,1.0)\n",
        "            rank_two = trial.suggest_uniform(name+'_two',0.0,1.0)\n",
        "            param.register_buffer('rank', torch.tensor([rank_one,rank_two]))# rank in, out\n",
        "            \n",
        "    compression_model = compression(lnames_to_compress, device, model_instance)\n",
        "    \n",
        "    macs = calc_macs(compression_model, (3, data_config[\"IMG_SIZE\"], data_config[\"IMG_SIZE\"]))\n",
        "\n",
        "    return macs"
      ],
      "id": "4efbd7ed-9f1d-4be4-b510-bfe903771aa0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c28e7d39-6884-4f3c-9855-73f6c9e07438"
      },
      "source": [
        "def objective_two(trial, device, model_config, data_config, model_path, original_macs):\n",
        "    \n",
        "    #create model_instance\n",
        "    \n",
        "    model_instance = Model(model_config,verbose=False)\n",
        "    \n",
        "    #filled best pretrained weight\n",
        "    \n",
        "    if os.path.isfile(model_path):\n",
        "        model_instance.model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    \n",
        "    #fixed hyperparameter \n",
        "\n",
        "    train_dl, val_dl, test_dl = create_dataloader(data_config)\n",
        "\n",
        "    train_path = os.path.join(data_config[\"DATA_PATH\"], \"train\")\n",
        "    save_path = os.path.join(log_dir, \"best.pt\")\n",
        "\n",
        "    criterion = CustomCriterion(\n",
        "        samples_per_cls=get_label_counts(train_path)\n",
        "        if data_config[\"DATASET\"] == \"TACO\"\n",
        "        else None,\n",
        "        device=device,\n",
        "        #loss_type=\"weighted\"\n",
        "        #loss_type=\"customloss\"\n",
        "        #loss_type=\"label_smoothing\"\n",
        "    )\n",
        "    \n",
        "    # Amp loss scaler\n",
        "    scaler = (\n",
        "        torch.cuda.amp.GradScaler() if data_config['FP16'] and device != torch.device(\"cpu\") else None\n",
        "    )\n",
        "    #scaler=None\n",
        "    \n",
        "    #rank hyperparameter\n",
        "    \n",
        "    rank = {}\n",
        "    \n",
        "    for name, param in model_instance.model.named_modules():\n",
        "        if isinstance(param, nn.Conv2d):\n",
        "            rank_one = trial.suggest_uniform(name+'_one',0.0,1.0)\n",
        "            rank_two = trial.suggest_uniform(name+'_two',0.0,1.0)\n",
        "            param.register_buffer('rank', torch.tensor([rank_one,rank_two]))# rank in, out\n",
        "            \n",
        "    compression_model = compression(lnames_to_compress, device, model_instance)\n",
        "    \n",
        "    macs = calc_macs(compression_model, (3, data_config[\"IMG_SIZE\"], data_config[\"IMG_SIZE\"]))\n",
        "    print(f\"macs: {macs}\")\n",
        "    \n",
        "    \n",
        "    if macs>original_macs:      ########\n",
        "        print(f' trial: {trial.number}, This model has very large macs:{macs}')\n",
        "        raise optuna.structs.TrialPruned()##############\n",
        "    \n",
        "    # Create optimizer, scheduler, criterion\n",
        "    optimizer = torch.optim.SGD(\n",
        "        compression_model.parameters(), lr=0.1, momentum=0.9\n",
        "    )\n",
        "    \n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer=optimizer,\n",
        "        max_lr=data_config[\"INIT_LR\"],\n",
        "        steps_per_epoch=len(train_dl),\n",
        "        epochs=30,\n",
        "        pct_start=0.05,\n",
        "    )\n",
        "\n",
        "    #scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,30,50,70,90,110,130,150,170,190], gamma=0.5)\n",
        "    \n",
        "    \n",
        "    _, best_f1 = train(\n",
        "        compression_model,\n",
        "        save_path,\n",
        "        optimizer,\n",
        "        scheduler, \n",
        "        criterion, \n",
        "        scaler, \n",
        "        train_dl, \n",
        "        val_dl, \n",
        "        device\n",
        "    )\n",
        "\n",
        "    return best_f1, macs"
      ],
      "id": "c28e7d39-6884-4f3c-9855-73f6c9e07438",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b43a9a55-76ab-4357-8a47-38f1bf88fe60"
      },
      "source": [
        "def tune_one(device, model_config, data_config, model_path, study_name= \"pstage_automl\"):\n",
        "    \n",
        "    sampler = optuna.samplers.TPESampler(n_startup_trials=20)\n",
        "\n",
        "    study = optuna.create_study(\n",
        "        direction=\"minimize\",\n",
        "        study_name=study_name,\n",
        "        sampler=sampler,\n",
        "        load_if_exists=True\n",
        "    )\n",
        "    \n",
        "    study.optimize(lambda trial: objective_one(trial, device, model_config, data_config, model_path), n_trials=15000)\n",
        "\n",
        "    pruned_trials = [\n",
        "        t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED\n",
        "    ]\n",
        "    complete_trials = [\n",
        "        t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE\n",
        "    ]\n",
        "\n",
        "    print(\"Study statistics: \")\n",
        "    print(\"  Number of finished trials: \", len(study.trials))\n",
        "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "    print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "    print(\"Best trials:\")\n",
        "    best_trials = study.best_trials\n",
        "\n",
        "    ## trials that satisfies Pareto Fronts\n",
        "    for tr in best_trials:\n",
        "        print(f\"  value:{tr.values}\")\n",
        "        for key, value in tr.params.items():\n",
        "            print(f\"    {key}:{value}\")\n",
        "\n",
        "    #best_trial = get_best_trial_with_condition(study)\n",
        "    \n",
        "    return study"
      ],
      "id": "b43a9a55-76ab-4357-8a47-38f1bf88fe60",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01e78389-33b9-4a79-ad53-8cfe4ae523db"
      },
      "source": [
        "def tune_two(device, model_config, data_config, model_path, study_name= \"pstage_automl\"):\n",
        "\n",
        "    sampler = optuna.samplers.MOTPESampler(n_startup_trials=20)\n",
        "\n",
        "    study = optuna.create_study(\n",
        "        directions=[\"maximize\", \"minimize\"],\n",
        "        study_name=study_name,\n",
        "        sampler=sampler,\n",
        "        load_if_exists=True\n",
        "    )\n",
        "    \n",
        "    study.optimize(lambda trial: objective_two(trial, device, model_config, data_config, model_path,original_macs), n_trials=100)\n",
        "\n",
        "    pruned_trials = [\n",
        "        t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED\n",
        "    ]\n",
        "    complete_trials = [\n",
        "        t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE\n",
        "    ]\n",
        "\n",
        "    print(\"Study statistics: \")\n",
        "    print(\"  Number of finished trials: \", len(study.trials))\n",
        "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "    print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "    print(\"Best trials:\")\n",
        "    best_trials = study.best_trials\n",
        "\n",
        "    ## trials that satisfies Pareto Fronts\n",
        "    for tr in best_trials:\n",
        "        print(f\"  value1:{tr.values[0]}, value2:{tr.values[1]}\")\n",
        "        for key, value in tr.params.items():\n",
        "            print(f\"    {key}:{value}\")\n",
        "\n",
        "    return study"
      ],
      "id": "01e78389-33b9-4a79-ad53-8cfe4ae523db",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "15023b58-549d-45db-83e3-c8a382d86966"
      },
      "source": [
        "study_name=\"pstage_automl\"\n",
        "\n",
        "study = tune_one(device, model_config, data_config, model_path, study_name=study_name)"
      ],
      "id": "15023b58-549d-45db-83e3-c8a382d86966",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "eaac97f4-b960-4de0-ad0d-1732842a9019"
      },
      "source": [
        "study_name=\"pstage_automl2\"\n",
        "\n",
        "study = tune_two(device, model_config, data_config, model_path, study_name=study_name)"
      ],
      "id": "eaac97f4-b960-4de0-ad0d-1732842a9019",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d033a387-f90e-4591-8229-b3c239b86703"
      },
      "source": [
        "## best parameter "
      ],
      "id": "d033a387-f90e-4591-8229-b3c239b86703"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "747cdc8b-1209-4772-bfbc-68d839f7335c"
      },
      "source": [
        "best_params = {'0.0.conv_one': 0.06249513139317668, '0.0.conv_two': 0.7406647857391946, '0.1.conv_one': 0.6363534088192819, '0.1.conv_two': 0.9142387393539608, '0.2.conv_one': 0.1292877468619793, '0.2.conv_two': 0.7383343969092988, '1.0.conv.0.0_one': 0.0008341748802290622, '1.0.conv.0.0_two': 0.05002966054540159, '1.0.conv.1.0_one': 0.8914359902260529, '1.0.conv.1.0_two': 0.002657766591352799, '1.0.conv.2_one': 0.06472996627499569, '1.0.conv.2_two': 0.0018459508866916843, '2.0.conv.0.0_one': 0.9115462763127067, '2.0.conv.0.0_two': 0.6639459793998597, '2.0.conv.1_one': 0.0853569870993198, '2.0.conv.1_two': 0.18126938180383792, '2.1.conv.0.0_one': 0.9817793298392701, '2.1.conv.0.0_two': 0.9001258631290798, '2.1.conv.1_one': 0.281183024423954, '2.1.conv.1_two': 0.8882239594838728, '2.2.conv.0.0_one': 0.17206134527733363, '2.2.conv.0.0_two': 0.8500281545934149, '2.2.conv.1_one': 0.14476380947875786, '2.2.conv.1_two': 0.005596879308822559, '2.3.conv.0.0_one': 0.44316357904486675, '2.3.conv.0.0_two': 0.5941322113050731, '2.3.conv.1_one': 0.572635098239233, '2.3.conv.1_two': 0.8468397676868743, '3.0.conv.0.0_one': 0.21862166138526337, '3.0.conv.0.0_two': 0.07024662744792722, '3.0.conv.1.0_one': 0.04545779266265461, '3.0.conv.1.0_two': 0.9045148663886942, '3.0.conv.2_one': 0.29411044633051125, '3.0.conv.2_two': 0.5847107548343258, '3.1.conv.0.0_one': 0.40518093356151513, '3.1.conv.0.0_two': 0.7475443817808775, '3.1.conv.1.0_one': 0.8043939144749847, '3.1.conv.1.0_two': 0.289022029677154, '3.1.conv.2_one': 0.0014290599572399554, '3.1.conv.2_two': 0.6629448092569628, '3.2.conv.0.0_one': 0.3641895413721229, '3.2.conv.0.0_two': 0.013451955264283952, '3.2.conv.1.0_one': 0.5363319490599914, '3.2.conv.1.0_two': 0.4116140987993332, '3.2.conv.2_one': 0.4913039777560289, '3.2.conv.2_two': 0.8455161001109379, '3.3.conv.0.0_one': 0.08959084143598055, '3.3.conv.0.0_two': 0.8011990428807316, '3.3.conv.1.0_one': 0.9341552726271395, '3.3.conv.1.0_two': 0.9627100873893634, '3.3.conv.2_one': 0.10003841299442714, '3.3.conv.2_two': 0.46928142816001717, '3.4.conv.0.0_one': 0.6525725884055026, '3.4.conv.0.0_two': 0.052133724856946936, '3.4.conv.1.0_one': 0.19177841739710982, '3.4.conv.1.0_two': 0.9318086669838463, '3.4.conv.2_one': 0.41486284037709126, '3.4.conv.2_two': 0.7832709259249746, '4.0.conv.0_one': 0.004875134710417898, '4.0.conv.0_two': 0.3262479183020909, '4.0.conv.3_one': 0.0012859373107223585, '4.0.conv.3_two': 0.19911844284242933, '4.0.conv.5.fc1_one': 0.32973034456086264, '4.0.conv.5.fc1_two': 0.30977965845059585, '4.0.conv.5.fc2_one': 0.16132036957829732, '4.0.conv.5.fc2_two': 0.9999374936964174, '4.0.conv.7_one': 0.09044786189188206, '4.0.conv.7_two': 0.10948415544559788, '4.1.conv.0_one': 2.315542203615295e-05, '4.1.conv.0_two': 0.08849056846575871, '4.1.conv.3_one': 0.769029022274578, '4.1.conv.3_two': 0.4263477411613994, '4.1.conv.5.fc1_one': 0.42351845543985933, '4.1.conv.5.fc1_two': 0.00549091928708752, '4.1.conv.5.fc2_one': 0.08237916516875739, '4.1.conv.5.fc2_two': 0.2120508770543559, '4.1.conv.7_one': 0.47650604499479804, '4.1.conv.7_two': 0.0006197777375650953, '5.conv_one': 0.00010686396333617018, '5.conv_two': 0.2755268916624911, '7.conv_one': 0.17916232010837874, '7.conv_two': 0.12058862027715131}"
      ],
      "id": "747cdc8b-1209-4772-bfbc-68d839f7335c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "4de62309-521f-4ab2-8086-0af52e92974c"
      },
      "source": [
        "study.best_trial.params"
      ],
      "id": "4de62309-521f-4ab2-8086-0af52e92974c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c19dbef-670c-4394-a631-b8b56bcb9cf5"
      },
      "source": [
        "## fine tuning"
      ],
      "id": "7c19dbef-670c-4394-a631-b8b56bcb9cf5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11dbb70c-c6a4-43ff-999d-19e2bc41dc34"
      },
      "source": [
        "#load model\n",
        "\n",
        "model_config = read_yaml(cfg=\"exp/0.5177_100epoch_1120/model.yml\")\n",
        "data_config = read_yaml(cfg=\"exp/0.5177_100epoch_1120/data.yml\")\n",
        "\n",
        "model_config = read_yaml(cfg=model_config)\n",
        "data_config = read_yaml(cfg=data_config)"
      ],
      "id": "11dbb70c-c6a4-43ff-999d-19e2bc41dc34",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54e3954e-26b9-409a-b43d-5b4b18cbfef0",
        "outputId": "6ca2e492-4dc5-48ae-db2f-53f43ef1ce36"
      },
      "source": [
        "model_instance = Model(model_config,verbose=True)"
      ],
      "id": "54e3954e-26b9-409a-b43d-5b4b18cbfef0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "idx |   n |     params |          module |            arguments |   in_channel |   out_channel\n",
            "----------------------------------------------------------------------------------------------\n",
            "  0 |   3 |        816 |          DWConv | [16, 3, 2, None, 'ReLU'] |            3           16\n",
            "  1 |   1 |      2,016 | InvertedResidualv2 |           [32, 2, 2] |           16           32\n",
            "  2 |   4 |      2,288 | InvertedResidualv2 |           [16, 1, 2] |           32           16\n",
            "  3 |   5 |      7,360 | InvertedResidualv2 |           [16, 2, 2] |           16           16\n",
            "  4 |   2 |    240,656 | InvertedResidualv3 | [5, 3.5, 128, 1, 1, 2] |           16          128\n",
            "  5 |   1 |     83,200 |            Conv |          [640, 1, 1] |          128          640\n",
            "  6 |   1 |          0 |   GlobalAvgPool |                   [] |          640          640\n",
            "  7 |   1 |      5,778 |       FixedConv | [9, 1, 1, None, 1, None] |          640            9\n",
            "Model Summary: 161 layers, 342,114 parameters, 342,114 gradients\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7401bb2-523e-4cef-abd2-5c16d612b7f3"
      },
      "source": [
        "model_path = 'exp/0.5177_100epoch_1120/best.pt'\n",
        "\n",
        "if os.path.isfile(model_path):\n",
        "    model_instance.model.load_state_dict(torch.load(model_path, map_location=device))"
      ],
      "id": "f7401bb2-523e-4cef-abd2-5c16d612b7f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "900321f0-b7e2-40db-ae46-b36f0c31d056"
      },
      "source": [
        "lnames_to_compress"
      ],
      "id": "900321f0-b7e2-40db-ae46-b36f0c31d056",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6a5f16c-0727-4b7f-92ba-ccbd179b8db9"
      },
      "source": [
        "#refine rank dictionary\n",
        "\n",
        "rank = {}\n",
        "\n",
        "for lname in lnames_to_compress:\n",
        "    \n",
        "    rank[lname] = [best_params[lname+'_one'],best_params[lname+'_two']]"
      ],
      "id": "f6a5f16c-0727-4b7f-92ba-ccbd179b8db9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "2cd59c65-25e6-467c-b925-8605e4190026"
      },
      "source": [
        "rank"
      ],
      "id": "2cd59c65-25e6-467c-b925-8605e4190026",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "264f4181-64e8-43f1-8928-9b06ea8b9fce"
      },
      "source": [
        "#create rank buffer\n",
        "\n",
        "for name, param in model_instance.model.named_modules():\n",
        "    if isinstance(param, nn.Conv2d):\n",
        "        if name in lnames_to_compress:\n",
        "            param.register_buffer('rank', torch.tensor(rank[name]))# rank in, out"
      ],
      "id": "264f4181-64e8-43f1-8928-9b06ea8b9fce",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "c2e58c27-bd9b-43de-a017-2c96c829becb"
      },
      "source": [
        "#compression\n",
        "\n",
        "for lname in lnames_to_compress:\n",
        "\n",
        "        ranks =  {k:None for k in all_layer}\n",
        "\n",
        "        for name, param in model_instance.model.named_modules():\n",
        "            if lname == name:\n",
        "                if param.groups == 1:\n",
        "                    tensor_rank = getattr(param, \"rank\")\n",
        "                    rank = [int(r * param.weight.shape[i]) for i, r in enumerate(tensor_rank)]\n",
        "                    ranks[lname] = [max(r, 2) for r in rank]\n",
        "                    break\n",
        "\n",
        "        if ranks[lname] == None:\n",
        "            continue\n",
        "\n",
        "        compressor = CompressorManual(model_instance.model, model_stats,ranks = ranks, ft_every = 1, conv2d_nn_decomposition='tucker2', nglobal_compress_iters = 1)\n",
        "\n",
        "        compressor.decompositions = {k:'tucker2' for k in compressor.decompositions.keys()}\n",
        "\n",
        "        while not compressor.done:\n",
        "            #print(\"\\n Compress\")\n",
        "            compressor.compression_step()\n",
        "\n",
        "            #print(\"\\n Calibrate\")\n",
        "            #compressor.model = calibrate(compressor.compressed_model, device, train_dl,freeze_lnames = lnames_to_compress[:idx])\n",
        "\n",
        "            compressor.compressed_model = compressor.compressed_model.to(device)\n",
        "\n",
        "            #macs = calc_macs(compressor.compressed_model, (3, data_config[\"IMG_SIZE\"], data_config[\"IMG_SIZE\"]))\n",
        "            #print(f\"macs: {macs}\")\n",
        "\n",
        "            #print(\"\\n Test\")\n",
        "            #test(compressor.compressed_model, device, val_dl)\n",
        "\n",
        "            #print('\\n Fine-tune')\n",
        "\n",
        "        model_instance.model = compressor.compressed_model"
      ],
      "id": "c2e58c27-bd9b-43de-a017-2c96c829becb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88842ecd-95c9-43a2-9d31-a9beb4012106"
      },
      "source": [
        "#calculate macs\n",
        "\n",
        "macs = calc_macs(model_instance.model, (3, data_config[\"IMG_SIZE\"], data_config[\"IMG_SIZE\"]))\n",
        "print(f\"macs: {macs}\")"
      ],
      "id": "88842ecd-95c9-43a2-9d31-a9beb4012106",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e0a898d-508d-4338-bcce-4a068ef7264b"
      },
      "source": [
        "log_dir = os.path.join(\"exp\", datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
        "os.makedirs(log_dir, exist_ok=True)"
      ],
      "id": "1e0a898d-508d-4338-bcce-4a068ef7264b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "519735fb-95cd-4a7f-92bc-4d5ecd6924e3"
      },
      "source": [
        "train_dl, val_dl, test_dl = create_dataloader(data_config)"
      ],
      "id": "519735fb-95cd-4a7f-92bc-4d5ecd6924e3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f52923e-bec7-42e0-9743-1ec7d28e5ad5"
      },
      "source": [
        "#hyperparameter \n",
        "\n",
        "train_path = os.path.join(data_config[\"DATA_PATH\"], \"train\")\n",
        "model_path = os.path.join(log_dir, \"best.pt\")\n",
        "\n",
        "# Create optimizer, scheduler, criterion\n",
        "optimizer = torch.optim.SGD(\n",
        "    model_instance.model.parameters(), lr=0.1, momentum=0.9\n",
        ")\n",
        "\n",
        "\n",
        "#scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    #optimizer=optimizer,\n",
        "    #max_lr=data_config[\"INIT_LR\"],\n",
        "    #steps_per_epoch=len(train_dl),\n",
        "    #epochs=200,\n",
        "    #pct_start=0.05,\n",
        "#)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,30,50,70,90,110,130,150,170,190], gamma=0.5)\n",
        "\n",
        "criterion = CustomCriterion(\n",
        "    samples_per_cls=get_label_counts(train_path)\n",
        "    if data_config[\"DATASET\"] == \"TACO\"\n",
        "    else None,\n",
        "    device=device,\n",
        "    #loss_type=\"weighted\"\n",
        "    #loss_type=\"customloss\"\n",
        "    #loss_type=\"label_smoothing\"\n",
        ")\n",
        "\n",
        "\n",
        "# Amp loss scaler\n",
        "scaler = (\n",
        "    torch.cuda.amp.GradScaler() if data_config['FP16'] and device != torch.device(\"cpu\") else None\n",
        ")\n",
        "#scaler=None"
      ],
      "id": "7f52923e-bec7-42e0-9743-1ec7d28e5ad5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "426ec137-c47a-4e36-ace3-013dd1c5c512"
      },
      "source": [
        "#test function\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model,test_dataloader):\n",
        "    \"\"\"Test model.\n",
        "\n",
        "    Args:\n",
        "        test_dataloader: test data loader module which is a iterator that returns (data, labels)\n",
        "\n",
        "    Returns:\n",
        "        loss, f1, accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    #n_batch = _get_n_batch_from_dataloader(test_dataloader)\n",
        "\n",
        "    running_loss = 0.0\n",
        "    preds = []\n",
        "    gt = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    num_classes = 9\n",
        "    label_list = [i for i in range(num_classes)]\n",
        "\n",
        "    pbar = notebook.tqdm(enumerate(test_dataloader), total=len(test_dataloader))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    for batch, (data, labels) in pbar:\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "        if scaler:\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(data)\n",
        "        else:\n",
        "            outputs = model(data)\n",
        "        outputs = torch.squeeze(outputs)\n",
        "        running_loss += criterion(outputs, labels).item()\n",
        "\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "\n",
        "        preds += pred.to(\"cpu\").tolist()\n",
        "        gt += labels.to(\"cpu\").tolist()\n",
        "        pbar.update()\n",
        "        pbar.set_description(\n",
        "            f\" Val: {'':5} Loss: {(running_loss / (batch + 1)):.3f}, \"\n",
        "            f\"Acc: {(correct / total) * 100:.2f}% \"\n",
        "            f\"F1(macro): {f1_score(y_true=gt, y_pred=preds, labels=label_list, average='macro', zero_division=0):.2f}\"\n",
        "        )\n",
        "    loss = running_loss / len(test_dataloader)\n",
        "    accuracy = correct / total\n",
        "    f1 = f1_score(\n",
        "        y_true=gt, y_pred=preds, labels=label_list, average=\"macro\", zero_division=0\n",
        "    )\n",
        "    \n",
        "    return loss, f1, accuracy"
      ],
      "id": "426ec137-c47a-4e36-ace3-013dd1c5c512",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "68a2b726-b616-4af4-979a-1b12303f41e1"
      },
      "source": [
        "#basic training\n",
        "n_epoch = 200\n",
        "\n",
        "best_test_acc = -1.0\n",
        "best_test_f1 = -1.0\n",
        "\n",
        "num_classes = 9\n",
        "\n",
        "label_list = [i for i in range(num_classes)]\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    preds, gt = [], []\n",
        "    pbar = notebook.tqdm(enumerate(train_dl), total=len(train_dl))\n",
        "    model_instance.model.train()\n",
        "    for batch, (data, labels) in pbar:\n",
        "        \n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "        if scaler:\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model_instance.model(data)\n",
        "        else:\n",
        "            outputs = model_instance.model(data)\n",
        "        outputs = torch.squeeze(outputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if scaler:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "        preds += pred.to(\"cpu\").tolist()\n",
        "        gt += labels.to(\"cpu\").tolist()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        pbar.update()\n",
        "        pbar.set_description(\n",
        "            f\"Train: [{epoch + 1:03d}] \"\n",
        "            f\"Loss: {(running_loss / (batch + 1)):.3f}, \"\n",
        "            f\"Acc: {(correct / total) * 100:.2f}% \"\n",
        "            f\"F1(macro): {f1_score(y_true=gt, y_pred=preds, labels=label_list, average='macro', zero_division=0):.2f}\"\n",
        "        )\n",
        "    pbar.close()\n",
        "\n",
        "    _, test_f1, test_acc = test(\n",
        "        model=model_instance.model, test_dataloader=val_dl\n",
        "    )\n",
        "    if best_test_f1 > test_f1:\n",
        "        continue\n",
        "    best_test_acc = test_acc\n",
        "    best_test_f1 = test_f1\n",
        "    print(f\"Model saved. Current best test f1: {best_test_f1:.3f}\")\n",
        "    save_model(\n",
        "        model=model_instance.model,\n",
        "        path=model_path,\n",
        "        data=data,\n",
        "        device=device,\n",
        "    )\n"
      ],
      "id": "68a2b726-b616-4af4-979a-1b12303f41e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f46d7565-a2ad-4e96-8e0e-e93720661a94"
      },
      "source": [
        "## calibrate compression"
      ],
      "id": "f46d7565-a2ad-4e96-8e0e-e93720661a94"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20a726f2-9cfb-4d75-8df5-ad1f5bf7c565"
      },
      "source": [
        "def calibrate(model, device, train_loader, max_iters = 1000,\n",
        "              freeze_lnames = None):\n",
        "\n",
        "    model.to(device).train()\n",
        "    for pname, p in model.named_parameters():\n",
        "        \n",
        "        if pname.strip('.weight').strip('.bias')  in freeze_lnames:\n",
        "            p.requires_grad = False\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (data, _) in notebook.tqdm(enumerate(train_loader)):\n",
        "            _ = model(data.to(device))\n",
        "\n",
        "            if i > max_iters:\n",
        "                break\n",
        "\n",
        "            del data\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "    model.eval()\n",
        "    return model"
      ],
      "id": "20a726f2-9cfb-4d75-8df5-ad1f5bf7c565",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "c1f9466d-aae6-4904-adaa-7c57ca34baf5"
      },
      "source": [
        "for idx,lname in enumerate(lnames_to_compress):\n",
        "\n",
        "        ranks =  {k:None for k in all_layer}\n",
        "\n",
        "        for name, param in model_instance.model.named_modules():\n",
        "            if lname == name:\n",
        "                if param.groups == 1:\n",
        "                    tensor_rank = getattr(param, \"rank\")\n",
        "                    rank = [int(r * param.weight.shape[i]) for i, r in enumerate(tensor_rank)]\n",
        "                    ranks[lname] = [max(r, 2) for r in rank]\n",
        "                    break\n",
        "\n",
        "        if ranks[lname] == None:\n",
        "            continue\n",
        "\n",
        "        compressor = CompressorManual(model_instance.model, model_stats,ranks = ranks, ft_every = 1, conv2d_nn_decomposition='tucker2', nglobal_compress_iters = 1)\n",
        "\n",
        "        compressor.decompositions = {k:'tucker2' for k in compressor.decompositions.keys()}\n",
        "\n",
        "        while not compressor.done:\n",
        "            print(\"\\n Compress\")\n",
        "            compressor.compression_step()\n",
        "\n",
        "            print(\"\\n Calibrate\")\n",
        "            compressor.model = calibrate(compressor.compressed_model, device, train_dl,freeze_lnames = lnames_to_compress[:idx])\n",
        "\n",
        "            compressor.compressed_model = compressor.compressed_model.to(device)\n",
        "\n",
        "            #macs = calc_macs(compressor.compressed_model, (3, data_config[\"IMG_SIZE\"], data_config[\"IMG_SIZE\"]))\n",
        "            #print(f\"macs: {macs}\")\n",
        "\n",
        "            #print(\"\\n Test\")\n",
        "            #test(compressor.compressed_model, device, val_dl)\n",
        "\n",
        "            #print('\\n Fine-tune')\n",
        "\n",
        "        model_instance.model = compressor.compressed_model"
      ],
      "id": "c1f9466d-aae6-4904-adaa-7c57ca34baf5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "c3cf7566-4b6b-40bf-a557-e01a89dd435d"
      },
      "source": [
        "#caculate macs\n",
        "macs = calc_macs(model_instance.model, (3, data_config[\"IMG_SIZE\"], data_config[\"IMG_SIZE\"]))\n",
        "print(f\"macs: {macs}\")"
      ],
      "id": "c3cf7566-4b6b-40bf-a557-e01a89dd435d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b89f56b8-286b-4772-aace-989adf7b736d"
      },
      "source": [
        "train_dl, val_dl, test_dl = create_dataloader(data_config)"
      ],
      "id": "b89f56b8-286b-4772-aace-989adf7b736d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dca1d1dc-e97f-4599-b52b-9d428d862283"
      },
      "source": [
        "#hyperparameter \n",
        "\n",
        "train_path = os.path.join(data_config[\"DATA_PATH\"], \"train\")\n",
        "model_path = os.path.join(log_dir, \"best.pt\")\n",
        "\n",
        "# Create optimizer, scheduler, criterion\n",
        "optimizer = torch.optim.SGD(\n",
        "    model_instance.model.parameters(), lr=0.1, momentum=0.9\n",
        ")\n",
        "\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer=optimizer,\n",
        "    max_lr=data_config[\"INIT_LR\"],\n",
        "    steps_per_epoch=len(train_dl),\n",
        "    epochs=200,\n",
        "    pct_start=0.05,\n",
        ")\n",
        "\n",
        "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,30,50,70,90,110,130,150,170,190], gamma=0.5)\n",
        "\n",
        "criterion = CustomCriterion(\n",
        "    samples_per_cls=get_label_counts(train_path)\n",
        "    if data_config[\"DATASET\"] == \"TACO\"\n",
        "    else None,\n",
        "    device=device,\n",
        "    #loss_type=\"weighted\"\n",
        "    #loss_type=\"customloss\"\n",
        "    #loss_type=\"label_smoothing\"\n",
        ")\n",
        "\n",
        "\n",
        "# Amp loss scaler\n",
        "scaler = (\n",
        "    torch.cuda.amp.GradScaler() if data_config['FP16'] and device != torch.device(\"cpu\") else None\n",
        ")\n",
        "#scaler=None"
      ],
      "id": "dca1d1dc-e97f-4599-b52b-9d428d862283",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "5bdcc31d-6061-4dbd-95b4-12fe7b4cf385"
      },
      "source": [
        "n_epoch = 200\n",
        "\n",
        "best_test_acc = -1.0\n",
        "best_test_f1 = -1.0\n",
        "\n",
        "num_classes = 9\n",
        "\n",
        "label_list = [i for i in range(num_classes)]\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    preds, gt = [], []\n",
        "    pbar = notebook.tqdm(enumerate(train_dl), total=len(train_dl))\n",
        "    model_instance.model.train()\n",
        "    for batch, (data, labels) in pbar:\n",
        "        \n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "        if scaler:\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model_instance.model(data)\n",
        "        else:\n",
        "            outputs = model_instance.model(data)\n",
        "        outputs = torch.squeeze(outputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if scaler:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "        preds += pred.to(\"cpu\").tolist()\n",
        "        gt += labels.to(\"cpu\").tolist()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        pbar.update()\n",
        "        pbar.set_description(\n",
        "            f\"Train: [{epoch + 1:03d}] \"\n",
        "            f\"Loss: {(running_loss / (batch + 1)):.3f}, \"\n",
        "            f\"Acc: {(correct / total) * 100:.2f}% \"\n",
        "            f\"F1(macro): {f1_score(y_true=gt, y_pred=preds, labels=label_list, average='macro', zero_division=0):.2f}\"\n",
        "        )\n",
        "    pbar.close()\n",
        "\n",
        "    _, test_f1, test_acc = test(\n",
        "        model=model_instance.model, test_dataloader=val_dl\n",
        "    )\n",
        "    if best_test_f1 > test_f1:\n",
        "        continue\n",
        "    best_test_acc = test_acc\n",
        "    best_test_f1 = test_f1\n",
        "    print(f\"Model saved. Current best test f1: {best_test_f1:.3f}\")\n",
        "    save_model(\n",
        "        model=model_instance.model,\n",
        "        path=model_path,\n",
        "        data=data,\n",
        "        device=device,\n",
        "    )\n"
      ],
      "id": "5bdcc31d-6061-4dbd-95b4-12fe7b4cf385",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a2927a5-a05e-4540-82db-6edf50b96419"
      },
      "source": [
        ""
      ],
      "id": "7a2927a5-a05e-4540-82db-6edf50b96419",
      "execution_count": null,
      "outputs": []
    }
  ]
}