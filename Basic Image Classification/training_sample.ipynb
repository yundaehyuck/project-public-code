{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tqdm\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam,lr_scheduler\n",
    "from functools import partial\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/data/train/train.csv')\n",
    "image_path = train['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_data = []\n",
    "\n",
    "for i in train['age']:\n",
    "    if i < 30:\n",
    "        category_data.append(0)\n",
    "    elif i < 60:\n",
    "        category_data.append(1)\n",
    "    else:\n",
    "        category_data.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cat_age']=category_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_class(mask,gender,age):\n",
    "    if mask == 0:\n",
    "        if gender == 'male':\n",
    "            if age == 0:\n",
    "                return 0\n",
    "            elif age == 1:\n",
    "                return 1\n",
    "            else:\n",
    "                return 2\n",
    "        else:\n",
    "            if age == 0:\n",
    "                return 3\n",
    "            elif age == 1:\n",
    "                return 4\n",
    "            else:\n",
    "                return 5\n",
    "    elif mask == 1:\n",
    "        if gender == 'male':\n",
    "            if age == 0:\n",
    "                return 6\n",
    "            elif age == 1:\n",
    "                return 7\n",
    "            else:\n",
    "                return 8\n",
    "        else:\n",
    "            if age == 0:\n",
    "                return 9\n",
    "            elif age == 1:\n",
    "                return 10\n",
    "            else:\n",
    "                return 11\n",
    "    else:\n",
    "        if gender == 'male':\n",
    "            if age == 0:\n",
    "                return 12\n",
    "            elif age == 1:\n",
    "                return 13\n",
    "            else:\n",
    "                return 14\n",
    "        else:\n",
    "            if age == 0:\n",
    "                return 15\n",
    "            elif age == 1:\n",
    "                return 16\n",
    "            else:\n",
    "                return 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_PIL_image(path):\n",
    "    \n",
    "    path_list = glob.glob('input/data/train/images/{}/*.*'.format(path))\n",
    "    image_list = []\n",
    "    str_ref = 'input/data/train/images/{}/'.format(path)\n",
    "    \n",
    "    \n",
    "    for i in path_list:\n",
    "        img = Image.open(i)\n",
    "        \n",
    "        if i[len(str_ref):-4] == 'normal':\n",
    "            img_mask = 2\n",
    "        elif i[len(str_ref):-4] == 'incorrect_mask':\n",
    "            img_mask = 1\n",
    "        else:\n",
    "            img_mask = 0\n",
    "        \n",
    "        image_list.append((img,img_mask))\n",
    "    \n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,image_path,gender,age,transform):\n",
    "        self.image_path = image_path\n",
    "        self.gender = gender\n",
    "        self.age = age\n",
    "        self.image_list = []\n",
    "        self.transform = transform\n",
    "        \n",
    "        for i,path in tqdm.tqdm(enumerate(self.image_path)):\n",
    "            img_list = data_PIL_image(path)\n",
    "            for img,mask in img_list:\n",
    "                c = torch.tensor([data_class(mask,self.gender[i],self.age[i])])\n",
    "                self.image_list.append((transform(img),c))\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.image_list[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = train['path']\n",
    "gender_list = train['gender']\n",
    "age_list =train['cat_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2700it [03:35, 12.52it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset(image_path = image_path, gender = gender_list, age=age_list,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self,num_channels=16):\n",
    "        super(ResBlock,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(num_channels,num_channels,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.leakyrelu = nn.LeakyReLU(negative_slope=0.2,inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(num_channels,num_channels,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.leakyrelu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "def make_block(r,n):\n",
    "    residual = []\n",
    "    \n",
    "    for i in range(r):\n",
    "        block = ResBlock(num_channels=n)\n",
    "        residual.append(block)\n",
    "    \n",
    "    return nn.Sequential(*residual)\n",
    "\n",
    "class ResizingNetwork(nn.Module):\n",
    "    def __init__(self,r=1, n=16):\n",
    "        super(ResizingNetwork, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=n,kernel_size=7,stride=1,padding=3)\n",
    "        self.leakyrelu1 = nn.LeakyReLU(negative_slope=0.2,inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(n,n,kernel_size=1,stride=1)\n",
    "        self.leakyrelu2 = nn.LeakyReLU(negative_slope=0.2,inplace=True)\n",
    "        self.bn1 = nn.BatchNorm2d(n)\n",
    "        \n",
    "        \n",
    "        self.resblock = make_block(r,n)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(n,n,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(n)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(n,out_channels=3,kernel_size=7,stride=1,padding=3)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        #residual = F.interpolate(x,scale_factor=1.5,mode='bilinear',align_corners=True,recompute_scale_factor=True)\n",
    "        residual = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.leakyrelu1(out)        \n",
    "        out = self.conv2(out)\n",
    "        out = self.leakyrelu2(out)\n",
    "        out = self.bn1(out)\n",
    "        \n",
    "        #out_residual = F.interpolate(out,scale_factor=1.5,mode='bilinear',align_corners=True,recompute_scale_factor=True)\n",
    "        out_residual = out\n",
    "\n",
    "        out = self.resblock(out_residual)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn2(out)\n",
    "        out += out_residual\n",
    "        out = self.conv4(out)\n",
    "        out += residual\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resizer = ResizingNetwork()\n",
    "rec_model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "resizer = ResizingNetwork()\n",
    "rec_model = timm.create_model('efficientnet_b0',pretrained=True,num_classes=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "resizer = ResizingNetwork()\n",
    "rec_model = timm.create_model('ecaresnet101d',pretrained=True,num_classes=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    }
   ],
   "source": [
    "resizer = ResizingNetwork()\n",
    "rec_model = EfficientNet.from_pretrained('efficientnet-b7',num_classes=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    }
   ],
   "source": [
    "resizer = ResizingNetwork()\n",
    "rec_model = EfficientNet.from_pretrained('efficientnet-b6',num_classes=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    }
   ],
   "source": [
    "resizer = ResizingNetwork()\n",
    "rec_model = EfficientNet.from_pretrained('efficientnet-b4',num_classes=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ecaresnet269d_320_ra2-7baa55cb.pth\" to /opt/ml/.cache/torch/hub/checkpoints/ecaresnet269d_320_ra2-7baa55cb.pth\n"
     ]
    }
   ],
   "source": [
    "resizer = ResizingNetwork()\n",
    "rec_model = timm.create_model('ecaresnet269d',pretrained=True,num_classes=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet50_ram-a26f946b.pth\" to /opt/ml/.cache/torch/hub/checkpoints/resnet50_ram-a26f946b.pth\n"
     ]
    }
   ],
   "source": [
    "resizer = ResizingNetwork()\n",
    "rec_model = timm.create_model('resnet50',pretrained=True,num_classes=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adv_inception_v3',\n",
      " 'cspdarknet53',\n",
      " 'cspresnet50',\n",
      " 'cspresnext50',\n",
      " 'densenet121',\n",
      " 'densenet161',\n",
      " 'densenet169',\n",
      " 'densenet201',\n",
      " 'densenetblur121d',\n",
      " 'dla34',\n",
      " 'dla46_c',\n",
      " 'dla46x_c',\n",
      " 'dla60',\n",
      " 'dla60_res2net',\n",
      " 'dla60_res2next',\n",
      " 'dla60x',\n",
      " 'dla60x_c',\n",
      " 'dla102',\n",
      " 'dla102x',\n",
      " 'dla102x2',\n",
      " 'dla169',\n",
      " 'dm_nfnet_f0',\n",
      " 'dm_nfnet_f1',\n",
      " 'dm_nfnet_f2',\n",
      " 'dm_nfnet_f3',\n",
      " 'dm_nfnet_f4',\n",
      " 'dm_nfnet_f5',\n",
      " 'dm_nfnet_f6',\n",
      " 'dpn68',\n",
      " 'dpn68b',\n",
      " 'dpn92',\n",
      " 'dpn98',\n",
      " 'dpn107',\n",
      " 'dpn131',\n",
      " 'ecaresnet26t',\n",
      " 'ecaresnet50d',\n",
      " 'ecaresnet50d_pruned',\n",
      " 'ecaresnet50t',\n",
      " 'ecaresnet101d',\n",
      " 'ecaresnet101d_pruned',\n",
      " 'ecaresnet269d',\n",
      " 'ecaresnetlight',\n",
      " 'efficientnet_b0',\n",
      " 'efficientnet_b1',\n",
      " 'efficientnet_b1_pruned',\n",
      " 'efficientnet_b2',\n",
      " 'efficientnet_b2_pruned',\n",
      " 'efficientnet_b2a',\n",
      " 'efficientnet_b3',\n",
      " 'efficientnet_b3_pruned',\n",
      " 'efficientnet_b3a',\n",
      " 'efficientnet_em',\n",
      " 'efficientnet_es',\n",
      " 'efficientnet_lite0',\n",
      " 'ens_adv_inception_resnet_v2',\n",
      " 'ese_vovnet19b_dw',\n",
      " 'ese_vovnet39b',\n",
      " 'fbnetc_100',\n",
      " 'gernet_l',\n",
      " 'gernet_m',\n",
      " 'gernet_s',\n",
      " 'gluon_inception_v3',\n",
      " 'gluon_resnet18_v1b',\n",
      " 'gluon_resnet34_v1b',\n",
      " 'gluon_resnet50_v1b',\n",
      " 'gluon_resnet50_v1c',\n",
      " 'gluon_resnet50_v1d',\n",
      " 'gluon_resnet50_v1s',\n",
      " 'gluon_resnet101_v1b',\n",
      " 'gluon_resnet101_v1c',\n",
      " 'gluon_resnet101_v1d',\n",
      " 'gluon_resnet101_v1s',\n",
      " 'gluon_resnet152_v1b',\n",
      " 'gluon_resnet152_v1c',\n",
      " 'gluon_resnet152_v1d',\n",
      " 'gluon_resnet152_v1s',\n",
      " 'gluon_resnext50_32x4d',\n",
      " 'gluon_resnext101_32x4d',\n",
      " 'gluon_resnext101_64x4d',\n",
      " 'gluon_senet154',\n",
      " 'gluon_seresnext50_32x4d',\n",
      " 'gluon_seresnext101_32x4d',\n",
      " 'gluon_seresnext101_64x4d',\n",
      " 'gluon_xception65',\n",
      " 'hrnet_w18',\n",
      " 'hrnet_w18_small',\n",
      " 'hrnet_w18_small_v2',\n",
      " 'hrnet_w30',\n",
      " 'hrnet_w32',\n",
      " 'hrnet_w40',\n",
      " 'hrnet_w44',\n",
      " 'hrnet_w48',\n",
      " 'hrnet_w64',\n",
      " 'ig_resnext101_32x8d',\n",
      " 'ig_resnext101_32x16d',\n",
      " 'ig_resnext101_32x32d',\n",
      " 'ig_resnext101_32x48d',\n",
      " 'inception_resnet_v2',\n",
      " 'inception_v3',\n",
      " 'inception_v4',\n",
      " 'legacy_senet154',\n",
      " 'legacy_seresnet18',\n",
      " 'legacy_seresnet34',\n",
      " 'legacy_seresnet50',\n",
      " 'legacy_seresnet101',\n",
      " 'legacy_seresnet152',\n",
      " 'legacy_seresnext26_32x4d',\n",
      " 'legacy_seresnext50_32x4d',\n",
      " 'legacy_seresnext101_32x4d',\n",
      " 'mixnet_l',\n",
      " 'mixnet_m',\n",
      " 'mixnet_s',\n",
      " 'mixnet_xl',\n",
      " 'mnasnet_100',\n",
      " 'mobilenetv2_100',\n",
      " 'mobilenetv2_110d',\n",
      " 'mobilenetv2_120d',\n",
      " 'mobilenetv2_140',\n",
      " 'mobilenetv3_large_100',\n",
      " 'mobilenetv3_rw',\n",
      " 'nasnetalarge',\n",
      " 'nf_regnet_b1',\n",
      " 'nf_resnet50',\n",
      " 'nfnet_l0c',\n",
      " 'pnasnet5large',\n",
      " 'regnetx_002',\n",
      " 'regnetx_004',\n",
      " 'regnetx_006',\n",
      " 'regnetx_008',\n",
      " 'regnetx_016',\n",
      " 'regnetx_032',\n",
      " 'regnetx_040',\n",
      " 'regnetx_064',\n",
      " 'regnetx_080',\n",
      " 'regnetx_120',\n",
      " 'regnetx_160',\n",
      " 'regnetx_320',\n",
      " 'regnety_002',\n",
      " 'regnety_004',\n",
      " 'regnety_006',\n",
      " 'regnety_008',\n",
      " 'regnety_016',\n",
      " 'regnety_032',\n",
      " 'regnety_040',\n",
      " 'regnety_064',\n",
      " 'regnety_080',\n",
      " 'regnety_120',\n",
      " 'regnety_160',\n",
      " 'regnety_320',\n",
      " 'repvgg_a2',\n",
      " 'repvgg_b0',\n",
      " 'repvgg_b1',\n",
      " 'repvgg_b1g4',\n",
      " 'repvgg_b2',\n",
      " 'repvgg_b2g4',\n",
      " 'repvgg_b3',\n",
      " 'repvgg_b3g4',\n",
      " 'res2net50_14w_8s',\n",
      " 'res2net50_26w_4s',\n",
      " 'res2net50_26w_6s',\n",
      " 'res2net50_26w_8s',\n",
      " 'res2net50_48w_2s',\n",
      " 'res2net101_26w_4s',\n",
      " 'res2next50',\n",
      " 'resnest14d',\n",
      " 'resnest26d',\n",
      " 'resnest50d',\n",
      " 'resnest50d_1s4x24d',\n",
      " 'resnest50d_4s2x40d',\n",
      " 'resnest101e',\n",
      " 'resnest200e',\n",
      " 'resnest269e',\n",
      " 'resnet18',\n",
      " 'resnet18d',\n",
      " 'resnet26',\n",
      " 'resnet26d',\n",
      " 'resnet34',\n",
      " 'resnet34d',\n",
      " 'resnet50',\n",
      " 'resnet50d',\n",
      " 'resnet101d',\n",
      " 'resnet152d',\n",
      " 'resnet200d',\n",
      " 'resnetblur50',\n",
      " 'resnetv2_50x1_bitm',\n",
      " 'resnetv2_50x1_bitm_in21k',\n",
      " 'resnetv2_50x3_bitm',\n",
      " 'resnetv2_50x3_bitm_in21k',\n",
      " 'resnetv2_101x1_bitm',\n",
      " 'resnetv2_101x1_bitm_in21k',\n",
      " 'resnetv2_101x3_bitm',\n",
      " 'resnetv2_101x3_bitm_in21k',\n",
      " 'resnetv2_152x2_bitm',\n",
      " 'resnetv2_152x2_bitm_in21k',\n",
      " 'resnetv2_152x4_bitm',\n",
      " 'resnetv2_152x4_bitm_in21k',\n",
      " 'resnext50_32x4d',\n",
      " 'resnext50d_32x4d',\n",
      " 'resnext101_32x8d',\n",
      " 'rexnet_100',\n",
      " 'rexnet_130',\n",
      " 'rexnet_150',\n",
      " 'rexnet_200',\n",
      " 'selecsls42b',\n",
      " 'selecsls60',\n",
      " 'selecsls60b',\n",
      " 'semnasnet_100',\n",
      " 'seresnet50',\n",
      " 'seresnet152d',\n",
      " 'seresnext26d_32x4d',\n",
      " 'seresnext26t_32x4d',\n",
      " 'seresnext50_32x4d',\n",
      " 'skresnet18',\n",
      " 'skresnet34',\n",
      " 'skresnext50_32x4d',\n",
      " 'spnasnet_100',\n",
      " 'ssl_resnet18',\n",
      " 'ssl_resnet50',\n",
      " 'ssl_resnext50_32x4d',\n",
      " 'ssl_resnext101_32x4d',\n",
      " 'ssl_resnext101_32x8d',\n",
      " 'ssl_resnext101_32x16d',\n",
      " 'swsl_resnet18',\n",
      " 'swsl_resnet50',\n",
      " 'swsl_resnext50_32x4d',\n",
      " 'swsl_resnext101_32x4d',\n",
      " 'swsl_resnext101_32x8d',\n",
      " 'swsl_resnext101_32x16d',\n",
      " 'tf_efficientnet_b0',\n",
      " 'tf_efficientnet_b0_ap',\n",
      " 'tf_efficientnet_b0_ns',\n",
      " 'tf_efficientnet_b1',\n",
      " 'tf_efficientnet_b1_ap',\n",
      " 'tf_efficientnet_b1_ns',\n",
      " 'tf_efficientnet_b2',\n",
      " 'tf_efficientnet_b2_ap',\n",
      " 'tf_efficientnet_b2_ns',\n",
      " 'tf_efficientnet_b3',\n",
      " 'tf_efficientnet_b3_ap',\n",
      " 'tf_efficientnet_b3_ns',\n",
      " 'tf_efficientnet_b4',\n",
      " 'tf_efficientnet_b4_ap',\n",
      " 'tf_efficientnet_b4_ns',\n",
      " 'tf_efficientnet_b5',\n",
      " 'tf_efficientnet_b5_ap',\n",
      " 'tf_efficientnet_b5_ns',\n",
      " 'tf_efficientnet_b6',\n",
      " 'tf_efficientnet_b6_ap',\n",
      " 'tf_efficientnet_b6_ns',\n",
      " 'tf_efficientnet_b7',\n",
      " 'tf_efficientnet_b7_ap',\n",
      " 'tf_efficientnet_b7_ns',\n",
      " 'tf_efficientnet_b8',\n",
      " 'tf_efficientnet_b8_ap',\n",
      " 'tf_efficientnet_cc_b0_4e',\n",
      " 'tf_efficientnet_cc_b0_8e',\n",
      " 'tf_efficientnet_cc_b1_8e',\n",
      " 'tf_efficientnet_el',\n",
      " 'tf_efficientnet_em',\n",
      " 'tf_efficientnet_es',\n",
      " 'tf_efficientnet_l2_ns',\n",
      " 'tf_efficientnet_l2_ns_475',\n",
      " 'tf_efficientnet_lite0',\n",
      " 'tf_efficientnet_lite1',\n",
      " 'tf_efficientnet_lite2',\n",
      " 'tf_efficientnet_lite3',\n",
      " 'tf_efficientnet_lite4',\n",
      " 'tf_inception_v3',\n",
      " 'tf_mixnet_l',\n",
      " 'tf_mixnet_m',\n",
      " 'tf_mixnet_s',\n",
      " 'tf_mobilenetv3_large_075',\n",
      " 'tf_mobilenetv3_large_100',\n",
      " 'tf_mobilenetv3_large_minimal_100',\n",
      " 'tf_mobilenetv3_small_075',\n",
      " 'tf_mobilenetv3_small_100',\n",
      " 'tf_mobilenetv3_small_minimal_100',\n",
      " 'tresnet_l',\n",
      " 'tresnet_l_448',\n",
      " 'tresnet_m',\n",
      " 'tresnet_m_448',\n",
      " 'tresnet_xl',\n",
      " 'tresnet_xl_448',\n",
      " 'tv_densenet121',\n",
      " 'tv_resnet34',\n",
      " 'tv_resnet50',\n",
      " 'tv_resnet101',\n",
      " 'tv_resnet152',\n",
      " 'tv_resnext50_32x4d',\n",
      " 'vgg11',\n",
      " 'vgg11_bn',\n",
      " 'vgg13',\n",
      " 'vgg13_bn',\n",
      " 'vgg16',\n",
      " 'vgg16_bn',\n",
      " 'vgg19',\n",
      " 'vgg19_bn',\n",
      " 'vit_base_patch16_224',\n",
      " 'vit_base_patch16_224_in21k',\n",
      " 'vit_base_patch16_384',\n",
      " 'vit_base_patch32_224_in21k',\n",
      " 'vit_base_patch32_384',\n",
      " 'vit_base_resnet50_224_in21k',\n",
      " 'vit_base_resnet50_384',\n",
      " 'vit_deit_base_distilled_patch16_224',\n",
      " 'vit_deit_base_distilled_patch16_384',\n",
      " 'vit_deit_base_patch16_224',\n",
      " 'vit_deit_base_patch16_384',\n",
      " 'vit_deit_small_distilled_patch16_224',\n",
      " 'vit_deit_small_patch16_224',\n",
      " 'vit_deit_tiny_distilled_patch16_224',\n",
      " 'vit_deit_tiny_patch16_224',\n",
      " 'vit_large_patch16_224',\n",
      " 'vit_large_patch16_224_in21k',\n",
      " 'vit_large_patch16_384',\n",
      " 'vit_large_patch32_224_in21k',\n",
      " 'vit_large_patch32_384',\n",
      " 'vit_small_patch16_224',\n",
      " 'wide_resnet50_2',\n",
      " 'wide_resnet101_2',\n",
      " 'xception',\n",
      " 'xception41',\n",
      " 'xception65',\n",
      " 'xception71']\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models(pretrained=True)\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_val = int(len(dataset) * 0.2)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=8,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=8,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CutMix(input,target,cutmix_prob,beta=1.0):\n",
    "    r = np.random.rand(1)\n",
    "    if beta > 0 and r < cutmix_prob:\n",
    "        lam = np.random.beta(beta, beta)\n",
    "        rand_index = torch.randperm(input.size()[0]).cuda()\n",
    "        target_a = target\n",
    "        target_b = target[rand_index]\n",
    "        bbx1, bby1, bbx2, bby2 = rand_bbox(input.size(), lam)\n",
    "        input[:, :, bbx1:bbx2, bby1:bby2] = input[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (input.size()[-1] * input.size()[-2]))\n",
    "        target_a = torch.nn.functional.one_hot(target_a, num_classes=18)\n",
    "        target_a = target_a.float()\n",
    "        target_b = torch.nn.functional.one_hot(target_b, num_classes=18)\n",
    "        target_b = target_b.float()\n",
    "        label = lam * target_a + (1.0-lam) * target_b\n",
    "        return input,label\n",
    "    else:\n",
    "        return input,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CutMix_two(input,target,cutmix_prob,beta=1.0):\n",
    "    r = np.random.rand(1)\n",
    "    if beta > 0 and r < cutmix_prob:\n",
    "        lam = np.random.beta(beta, beta)\n",
    "        rand_index = torch.randperm(input.size()[0]).cuda()\n",
    "        target_a = target\n",
    "        target_b = target[rand_index]\n",
    "        bbx1, bby1, bbx2, bby2 = rand_bbox(input.size(), lam)\n",
    "        input[:, :, bbx1:bbx2, bby1:bby2] = input[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (input.size()[-1] * input.size()[-2]))\n",
    "        return input,lam,target_a,target_b,True\n",
    "    else:\n",
    "        lam = np.random.beta(beta, beta)\n",
    "        return input,lam,target,target,False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0, use_cuda=False):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self,classes=18,smoothing=0.1,dim=-1):\n",
    "        super(LabelSmoothingLoss,self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self,pred,target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing/self.cls)\n",
    "            true_dist.scatter_(1,target.data,(1.0-self.smoothing))\n",
    "        return torch.mean(torch.sum(-true_dist*pred,dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CutMixcrossentropyloss(nn.Module):\n",
    "    def __init__(self,classes=18,smoothing=0.1,dim=-1):\n",
    "        super(CutMixcrossentropyloss,self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "        \n",
    "    def forward(self,pred,target):\n",
    "        if len(target.shape) == 3: \n",
    "            pred = pred.log_softmax(dim=self.dim)\n",
    "            return torch.mean(torch.sum(-target*pred,dim=self.dim))\n",
    "        else:\n",
    "            pred = pred.log_softmax(dim=self.dim)\n",
    "            with torch.no_grad():\n",
    "                true_dist = torch.zeros_like(pred)\n",
    "                true_dist.fill_(self.smoothing/self.cls)\n",
    "                true_dist.scatter_(1,target.data,(1.0-self.smoothing))\n",
    "            return torch.mean(torch.sum(-true_dist*pred,dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mymodel(nn.Module):\n",
    "    def __init__(self,resizer,recognition):\n",
    "        super(Mymodel,self).__init__()\n",
    "        self.resizer = resizer\n",
    "        self.recognition = recognition\n",
    "    \n",
    "    def forward(self,x):\n",
    "        resize_img = self.resizer(x)\n",
    "        output = self.recognition(resize_img)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adamp import AdamP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from madgrad import MADGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = LabelSmoothingLoss()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=2,eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = LabelSmoothingLoss()\n",
    "optimizer = AdamP(model.parameters(),lr=0.001,weight_decay=0.01)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer,milestones=[4,7],gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = LabelSmoothingLoss()\n",
    "optimizer = MADGRAD(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = LabelSmoothingLoss()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer,milestones=[4,7],gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CutMixcrossentropyloss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.7,weight_decay=0.01)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=2,eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "patience = 10\n",
    "best_val_acc = 0\n",
    "best_val_loss = np.inf\n",
    "train_log_interval = 100\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/5](100/1890) || training loss 1.054 || training accuracy 60.38% || lr [0.0010000000000000026]||fl_score_train : 0.5519310966810967\n",
      "Epoch[0/5](200/1890) || training loss 1.115 || training accuracy 58.63% || lr [0.0010000000000000026]||fl_score_train : 0.5337315003779288\n",
      "Epoch[0/5](300/1890) || training loss 1.066 || training accuracy 64.00% || lr [0.0010000000000000026]||fl_score_train : 0.5924376984126984\n",
      "Epoch[0/5](400/1890) || training loss 1.127 || training accuracy 58.38% || lr [0.0010000000000000026]||fl_score_train : 0.5236261063011062\n",
      "Epoch[0/5](500/1890) || training loss 1.071 || training accuracy 60.62% || lr [0.0010000000000000026]||fl_score_train : 0.5614214285714286\n",
      "Epoch[0/5](600/1890) || training loss 1.114 || training accuracy 62.00% || lr [0.0010000000000000026]||fl_score_train : 0.5725864117364117\n",
      "Epoch[0/5](700/1890) || training loss 1.099 || training accuracy 60.12% || lr [0.0010000000000000026]||fl_score_train : 0.5553904761904764\n",
      "Epoch[0/5](800/1890) || training loss 1.123 || training accuracy 62.50% || lr [0.0010000000000000026]||fl_score_train : 0.5715226190476193\n",
      "Epoch[0/5](900/1890) || training loss 1.111 || training accuracy 61.12% || lr [0.0010000000000000026]||fl_score_train : 0.5568613756613755\n",
      "Epoch[0/5](1000/1890) || training loss 1.071 || training accuracy 63.75% || lr [0.0010000000000000026]||fl_score_train : 0.5947833333333334\n",
      "Epoch[0/5](1100/1890) || training loss 1.098 || training accuracy 57.63% || lr [0.0010000000000000026]||fl_score_train : 0.5234138888888888\n",
      "Epoch[0/5](1200/1890) || training loss 1.136 || training accuracy 54.75% || lr [0.0010000000000000026]||fl_score_train : 0.48480383597883586\n",
      "Epoch[0/5](1300/1890) || training loss 1.112 || training accuracy 59.25% || lr [0.0010000000000000026]||fl_score_train : 0.5487811327561328\n",
      "Epoch[0/5](1400/1890) || training loss 1.097 || training accuracy 62.25% || lr [0.0010000000000000026]||fl_score_train : 0.5685420634920636\n",
      "Epoch[0/5](1500/1890) || training loss 1.096 || training accuracy 55.00% || lr [0.0010000000000000026]||fl_score_train : 0.5016217120181405\n",
      "Epoch[0/5](1600/1890) || training loss 1.119 || training accuracy 59.50% || lr [0.0010000000000000026]||fl_score_train : 0.5343761904761903\n",
      "Epoch[0/5](1700/1890) || training loss 1.142 || training accuracy 58.13% || lr [0.0010000000000000026]||fl_score_train : 0.5283853174603175\n",
      "Epoch[0/5](1800/1890) || training loss 1.102 || training accuracy 66.38% || lr [0.0010000000000000026]||fl_score_train : 0.6146540764790768\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 96.72%, loss: 0.68 || f1_score: 0.9425003076165868 ||best acc : 96.72%, best loss: 0.68\n",
      "Epoch[1/5](100/1890) || training loss 1.112 || training accuracy 58.13% || lr [0.0010000000000000026]||fl_score_train : 0.5280461829176117\n",
      "Epoch[1/5](200/1890) || training loss 1.12 || training accuracy 62.88% || lr [0.0010000000000000026]||fl_score_train : 0.5645512987012988\n",
      "Epoch[1/5](300/1890) || training loss 1.129 || training accuracy 59.88% || lr [0.0010000000000000026]||fl_score_train : 0.5447781746031746\n",
      "Epoch[1/5](400/1890) || training loss 1.086 || training accuracy 63.75% || lr [0.0010000000000000026]||fl_score_train : 0.5960251924001925\n",
      "Epoch[1/5](500/1890) || training loss 1.073 || training accuracy 60.38% || lr [0.0010000000000000026]||fl_score_train : 0.5585816257816257\n",
      "Epoch[1/5](600/1890) || training loss 1.165 || training accuracy 54.25% || lr [0.0010000000000000026]||fl_score_train : 0.4801527777777779\n",
      "Epoch[1/5](700/1890) || training loss 1.116 || training accuracy 59.38% || lr [0.0010000000000000026]||fl_score_train : 0.5419373015873016\n",
      "Epoch[1/5](800/1890) || training loss 1.074 || training accuracy 63.38% || lr [0.0010000000000000026]||fl_score_train : 0.5925260822510822\n",
      "Epoch[1/5](900/1890) || training loss 1.041 || training accuracy 62.12% || lr [0.0010000000000000026]||fl_score_train : 0.5653522486772488\n",
      "Epoch[1/5](1000/1890) || training loss 1.097 || training accuracy 62.38% || lr [0.0010000000000000026]||fl_score_train : 0.5771300865800866\n",
      "Epoch[1/5](1100/1890) || training loss 1.083 || training accuracy 69.12% || lr [0.0010000000000000026]||fl_score_train : 0.6381064102564102\n",
      "Epoch[1/5](1200/1890) || training loss 1.116 || training accuracy 63.88% || lr [0.0010000000000000026]||fl_score_train : 0.5922194203944207\n",
      "Epoch[1/5](1300/1890) || training loss 1.145 || training accuracy 58.13% || lr [0.0010000000000000026]||fl_score_train : 0.5219985638699923\n",
      "Epoch[1/5](1400/1890) || training loss 1.087 || training accuracy 59.62% || lr [0.0010000000000000026]||fl_score_train : 0.5400535714285717\n",
      "Epoch[1/5](1500/1890) || training loss 1.143 || training accuracy 56.50% || lr [0.0010000000000000026]||fl_score_train : 0.5133939033189034\n",
      "Epoch[1/5](1600/1890) || training loss 1.139 || training accuracy 54.25% || lr [0.0010000000000000026]||fl_score_train : 0.48497579365079374\n",
      "Epoch[1/5](1700/1890) || training loss 1.103 || training accuracy 58.25% || lr [0.0010000000000000026]||fl_score_train : 0.5203654761904761\n",
      "Epoch[1/5](1800/1890) || training loss 1.101 || training accuracy 63.12% || lr [0.0010000000000000026]||fl_score_train : 0.5834340548340549\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 98.44%, loss: 0.64 || f1_score: 0.9721629259472813 ||best acc : 98.44%, best loss: 0.64\n",
      "Epoch[2/5](100/1890) || training loss 1.113 || training accuracy 59.88% || lr [0.0010000000000000026]||fl_score_train : 0.5390369047619049\n",
      "Epoch[2/5](200/1890) || training loss 1.084 || training accuracy 66.62% || lr [0.0010000000000000026]||fl_score_train : 0.609613492063492\n",
      "Epoch[2/5](300/1890) || training loss 1.084 || training accuracy 61.12% || lr [0.0010000000000000026]||fl_score_train : 0.5634439342403627\n",
      "Epoch[2/5](400/1890) || training loss 1.123 || training accuracy 57.50% || lr [0.0010000000000000026]||fl_score_train : 0.5147181216931218\n",
      "Epoch[2/5](500/1890) || training loss 1.067 || training accuracy 61.12% || lr [0.0010000000000000026]||fl_score_train : 0.5583433862433861\n",
      "Epoch[2/5](600/1890) || training loss 1.049 || training accuracy 60.38% || lr [0.0010000000000000026]||fl_score_train : 0.5666755050505052\n",
      "Epoch[2/5](700/1890) || training loss 1.144 || training accuracy 56.50% || lr [0.0010000000000000026]||fl_score_train : 0.5117695767195767\n",
      "Epoch[2/5](800/1890) || training loss 1.093 || training accuracy 59.50% || lr [0.0010000000000000026]||fl_score_train : 0.5397142857142856\n",
      "Epoch[2/5](900/1890) || training loss 1.097 || training accuracy 61.50% || lr [0.0010000000000000026]||fl_score_train : 0.5588504810004808\n",
      "Epoch[2/5](1000/1890) || training loss 1.094 || training accuracy 63.00% || lr [0.0010000000000000026]||fl_score_train : 0.5757750000000001\n",
      "Epoch[2/5](1100/1890) || training loss 1.108 || training accuracy 63.25% || lr [0.0010000000000000026]||fl_score_train : 0.5847936507936509\n",
      "Epoch[2/5](1200/1890) || training loss 1.052 || training accuracy 60.88% || lr [0.0010000000000000026]||fl_score_train : 0.5581042517006803\n",
      "Epoch[2/5](1300/1890) || training loss 1.084 || training accuracy 58.13% || lr [0.0010000000000000026]||fl_score_train : 0.5262924963924965\n",
      "Epoch[2/5](1400/1890) || training loss 1.076 || training accuracy 60.62% || lr [0.0010000000000000026]||fl_score_train : 0.5589306122448979\n",
      "Epoch[2/5](1500/1890) || training loss 1.102 || training accuracy 63.62% || lr [0.0010000000000000026]||fl_score_train : 0.5923883597883598\n",
      "Epoch[2/5](1600/1890) || training loss 1.101 || training accuracy 64.62% || lr [0.0010000000000000026]||fl_score_train : 0.6081059523809521\n",
      "Epoch[2/5](1700/1890) || training loss 1.153 || training accuracy 57.12% || lr [0.0010000000000000026]||fl_score_train : 0.5036150072150073\n",
      "Epoch[2/5](1800/1890) || training loss 1.118 || training accuracy 58.38% || lr [0.0010000000000000026]||fl_score_train : 0.5226713718820863\n",
      "Calculating validation results...\n",
      "[Val] acc : 96.49%, loss: 0.69 || f1_score: 0.9395224977043152 ||best acc : 98.44%, best loss: 0.64\n",
      "Epoch[3/5](100/1890) || training loss 1.096 || training accuracy 63.75% || lr [0.0010000000000000026]||fl_score_train : 0.5929932539682541\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-a1bc69dcdf93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/madgrad/madgrad.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                         \u001b[0;31m# p is a moving average of z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mck\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mck\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#mixup training\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train loop\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    train_acc = 0 \n",
    "    train_f1 = 0\n",
    "    for idx, (inputs,targets) in enumerate(train_loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs,target_a,target_b,lam = mixup_data(inputs,targets,alpha=1.0)\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        \n",
    "        target_a = target_a.to(device)\n",
    "        target_b = target_b.to(device)\n",
    "        \n",
    "        loss = criterion(outs, target_a) * lam + criterion(outs, target_b)* (1-lam)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        loss_value += loss.item()\n",
    "        train_acc += accuracy_score(targets.cpu(),preds.cpu())\n",
    "        train_f1 += f1_score(targets.cpu(),preds.cpu(),average='macro')\n",
    "\n",
    "        if (idx + 1) % train_log_interval == 0:\n",
    "            train_loss = loss_value / train_log_interval\n",
    "            avg_train_acc = train_acc / train_log_interval\n",
    "            avg_train_f1 = train_f1 / train_log_interval\n",
    "            \n",
    "            current_lr = scheduler.get_last_lr()\n",
    "\n",
    "            print(\n",
    "                f\"Epoch[{epoch}/{num_epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                f\"training loss {train_loss:4.4} || training accuracy {avg_train_acc:4.2%} || lr {current_lr}||\"\n",
    "                \"fl_score_train : {}\".format(avg_train_f1)\n",
    "            )\n",
    "\n",
    "            loss_value = 0\n",
    "            train_acc = 0\n",
    "            train_f1 = 0\n",
    "\n",
    "    #scheduler.step()\n",
    "\n",
    "    # val loop\n",
    "    with torch.no_grad():\n",
    "        print(\"Calculating validation results...\")\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_f1 = 0\n",
    "        val_acc = 0\n",
    "        for idx,(inputs,labels) in enumerate(val_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "            \n",
    "            val_acc += accuracy_score(labels.cpu(),preds.cpu())\n",
    "            val_f1 += f1_score(labels.cpu(),preds.cpu(),average='macro')\n",
    "            \n",
    "            loss_item = criterion(outs, labels).item()\n",
    "            val_loss_items.append(loss_item)\n",
    "\n",
    "        val_loss = np.sum(val_loss_items) / len(val_loader)\n",
    "        avg_val_acc = val_acc / (idx+1)\n",
    "        avg_val_f1 = val_f1 / (idx+1)\n",
    "        \n",
    "        \n",
    "        # Callback1: validation accuracy가 향상될수록 모델을 저장합니다.\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "        if avg_val_acc > best_val_acc:\n",
    "            print(\"New best model for val accuracy! saving the model..\")\n",
    "            torch.save(model.state_dict(), f\"result_{epoch:03}_accuracy_{avg_val_acc:4.2%}.ckpt\")\n",
    "            best_val_acc = avg_val_acc\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        # Callback2: patience 횟수 동안 성능 향상이 없을 경우 학습을 종료시킵니다.\n",
    "        if counter > patience:\n",
    "            print(\"Early Stopping...\")\n",
    "            break\n",
    "        \n",
    "        \n",
    "        print(\n",
    "            f\"[Val] acc : {avg_val_acc:4.2%}, loss: {val_loss:4.2} || f1_score: {avg_val_f1} ||\"\n",
    "            f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/5](100/1890) || training loss 0.8697 || training accuracy 87.00% || lr [0.00025]||fl_score_train : 0.8478851130351133\n",
      "Epoch[0/5](200/1890) || training loss 0.8327 || training accuracy 89.25% || lr [0.00025]||fl_score_train : 0.8673465075929362\n",
      "Epoch[0/5](300/1890) || training loss 0.8255 || training accuracy 88.75% || lr [0.00025]||fl_score_train : 0.8683351319315606\n",
      "Epoch[0/5](400/1890) || training loss 0.8133 || training accuracy 90.62% || lr [0.00025]||fl_score_train : 0.8870468253968252\n",
      "Epoch[0/5](500/1890) || training loss 0.8398 || training accuracy 90.75% || lr [0.00025]||fl_score_train : 0.8868373015873015\n",
      "Epoch[0/5](600/1890) || training loss 0.8379 || training accuracy 87.25% || lr [0.00025]||fl_score_train : 0.8487884920634918\n",
      "Epoch[0/5](700/1890) || training loss 0.8047 || training accuracy 91.75% || lr [0.00025]||fl_score_train : 0.9059333333333334\n",
      "Epoch[0/5](800/1890) || training loss 0.867 || training accuracy 89.12% || lr [0.00025]||fl_score_train : 0.8636369047619047\n",
      "Epoch[0/5](900/1890) || training loss 0.8767 || training accuracy 88.62% || lr [0.00025]||fl_score_train : 0.8634346681096683\n",
      "Epoch[0/5](1000/1890) || training loss 0.8238 || training accuracy 92.88% || lr [0.00025]||fl_score_train : 0.9173502645502646\n",
      "Epoch[0/5](1100/1890) || training loss 0.9001 || training accuracy 84.88% || lr [0.00025]||fl_score_train : 0.8156941798941797\n",
      "Epoch[0/5](1200/1890) || training loss 0.8472 || training accuracy 89.25% || lr [0.00025]||fl_score_train : 0.8734363756613756\n",
      "Epoch[0/5](1300/1890) || training loss 0.869 || training accuracy 87.75% || lr [0.00025]||fl_score_train : 0.8533266955266957\n",
      "Epoch[0/5](1400/1890) || training loss 0.8789 || training accuracy 86.75% || lr [0.00025]||fl_score_train : 0.8430519841269841\n",
      "Epoch[0/5](1500/1890) || training loss 0.8777 || training accuracy 84.12% || lr [0.00025]||fl_score_train : 0.8035711399711402\n",
      "Epoch[0/5](1600/1890) || training loss 0.8978 || training accuracy 86.00% || lr [0.00025]||fl_score_train : 0.8431685185185187\n",
      "Epoch[0/5](1700/1890) || training loss 0.8406 || training accuracy 89.75% || lr [0.00025]||fl_score_train : 0.8803460317460317\n",
      "Epoch[0/5](1800/1890) || training loss 0.8338 || training accuracy 90.12% || lr [0.00025]||fl_score_train : 0.8729579365079365\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 99.47%, loss:  0.6 || f1_score: 0.9903641061780595 ||best acc : 99.47%, best loss:  0.6\n",
      "Epoch[1/5](100/1890) || training loss 0.8001 || training accuracy 92.62% || lr [0.00025]||fl_score_train : 0.9087451058201057\n",
      "Epoch[1/5](200/1890) || training loss 0.8509 || training accuracy 88.75% || lr [0.00025]||fl_score_train : 0.8632595238095234\n",
      "Epoch[1/5](300/1890) || training loss 0.7842 || training accuracy 90.75% || lr [0.00025]||fl_score_train : 0.8914574074074075\n",
      "Epoch[1/5](400/1890) || training loss 0.9044 || training accuracy 86.12% || lr [0.00025]||fl_score_train : 0.8447063492063491\n",
      "Epoch[1/5](500/1890) || training loss 0.8474 || training accuracy 90.00% || lr [0.00025]||fl_score_train : 0.8841346320346318\n",
      "Epoch[1/5](600/1890) || training loss 0.8441 || training accuracy 88.75% || lr [0.00025]||fl_score_train : 0.8678634310134311\n",
      "Epoch[1/5](700/1890) || training loss 0.894 || training accuracy 85.75% || lr [0.00025]||fl_score_train : 0.8316351130351128\n",
      "Epoch[1/5](800/1890) || training loss 0.8191 || training accuracy 91.00% || lr [0.00025]||fl_score_train : 0.8820987012987012\n",
      "Epoch[1/5](900/1890) || training loss 0.876 || training accuracy 86.12% || lr [0.00025]||fl_score_train : 0.8336460317460318\n",
      "Epoch[1/5](1000/1890) || training loss 0.8506 || training accuracy 87.50% || lr [0.00025]||fl_score_train : 0.8572793650793652\n",
      "Epoch[1/5](1100/1890) || training loss 0.8214 || training accuracy 88.75% || lr [0.00025]||fl_score_train : 0.8704472789115644\n",
      "Epoch[1/5](1200/1890) || training loss 0.831 || training accuracy 89.50% || lr [0.00025]||fl_score_train : 0.8808563492063493\n",
      "Epoch[1/5](1300/1890) || training loss 0.8939 || training accuracy 86.25% || lr [0.00025]||fl_score_train : 0.8318009448223733\n",
      "Epoch[1/5](1400/1890) || training loss 0.7776 || training accuracy 91.12% || lr [0.00025]||fl_score_train : 0.8946174603174604\n",
      "Epoch[1/5](1500/1890) || training loss 0.8734 || training accuracy 89.00% || lr [0.00025]||fl_score_train : 0.8588222222222224\n",
      "Epoch[1/5](1600/1890) || training loss 0.8791 || training accuracy 88.50% || lr [0.00025]||fl_score_train : 0.8590706349206352\n",
      "Epoch[1/5](1700/1890) || training loss 0.8858 || training accuracy 87.00% || lr [0.00025]||fl_score_train : 0.851326984126984\n",
      "Epoch[1/5](1800/1890) || training loss 0.8419 || training accuracy 88.50% || lr [0.00025]||fl_score_train : 0.8556865199615197\n",
      "Calculating validation results...\n",
      "[Val] acc : 99.47%, loss:  0.6 || f1_score: 0.991410724581972 ||best acc : 99.47%, best loss:  0.6\n",
      "Epoch[2/5](100/1890) || training loss 0.8653 || training accuracy 89.62% || lr [0.00025]||fl_score_train : 0.8757849206349205\n",
      "Epoch[2/5](200/1890) || training loss 0.8676 || training accuracy 90.12% || lr [0.00025]||fl_score_train : 0.8730031237281234\n",
      "Epoch[2/5](300/1890) || training loss 0.8369 || training accuracy 87.88% || lr [0.00025]||fl_score_train : 0.8579761904761903\n",
      "Epoch[2/5](400/1890) || training loss 0.7781 || training accuracy 93.25% || lr [0.00025]||fl_score_train : 0.920031216931217\n",
      "Epoch[2/5](500/1890) || training loss 0.8652 || training accuracy 84.12% || lr [0.00025]||fl_score_train : 0.8212507936507936\n",
      "Epoch[2/5](600/1890) || training loss 0.8599 || training accuracy 91.50% || lr [0.00025]||fl_score_train : 0.8936055555555553\n",
      "Epoch[2/5](700/1890) || training loss 0.8618 || training accuracy 89.25% || lr [0.00025]||fl_score_train : 0.8724564814814815\n",
      "Epoch[2/5](800/1890) || training loss 0.8506 || training accuracy 90.00% || lr [0.00025]||fl_score_train : 0.8786440476190474\n",
      "Epoch[2/5](900/1890) || training loss 0.81 || training accuracy 90.25% || lr [0.00025]||fl_score_train : 0.8800054112554113\n",
      "Epoch[2/5](1000/1890) || training loss 0.8619 || training accuracy 84.62% || lr [0.00025]||fl_score_train : 0.821023015873016\n",
      "Epoch[2/5](1100/1890) || training loss 0.8041 || training accuracy 91.38% || lr [0.00025]||fl_score_train : 0.9023159090909091\n",
      "Epoch[2/5](1200/1890) || training loss 0.8044 || training accuracy 91.25% || lr [0.00025]||fl_score_train : 0.8965690476190475\n",
      "Epoch[2/5](1300/1890) || training loss 0.8507 || training accuracy 88.50% || lr [0.00025]||fl_score_train : 0.8610728835978834\n",
      "Epoch[2/5](1400/1890) || training loss 0.8633 || training accuracy 88.00% || lr [0.00025]||fl_score_train : 0.856045238095238\n",
      "Epoch[2/5](1500/1890) || training loss 0.8346 || training accuracy 90.38% || lr [0.00025]||fl_score_train : 0.8852392857142855\n",
      "Epoch[2/5](1600/1890) || training loss 0.8186 || training accuracy 87.88% || lr [0.00025]||fl_score_train : 0.8512174603174604\n",
      "Epoch[2/5](1700/1890) || training loss 0.8462 || training accuracy 91.38% || lr [0.00025]||fl_score_train : 0.8891821428571426\n",
      "Epoch[2/5](1800/1890) || training loss 0.8301 || training accuracy 89.75% || lr [0.00025]||fl_score_train : 0.8809834415584413\n",
      "Calculating validation results...\n",
      "[Val] acc : 99.45%, loss:  0.6 || f1_score: 0.9906936474378335 ||best acc : 99.47%, best loss:  0.6\n",
      "Epoch[3/5](100/1890) || training loss 0.8654 || training accuracy 90.50% || lr [0.00025]||fl_score_train : 0.8824028860028861\n",
      "Epoch[3/5](200/1890) || training loss 0.8853 || training accuracy 90.25% || lr [0.00025]||fl_score_train : 0.8783663308913308\n",
      "Epoch[3/5](300/1890) || training loss 0.8415 || training accuracy 85.88% || lr [0.00025]||fl_score_train : 0.8473511904761903\n",
      "Epoch[3/5](400/1890) || training loss 0.8647 || training accuracy 88.50% || lr [0.00025]||fl_score_train : 0.8581162698412697\n",
      "Epoch[3/5](500/1890) || training loss 0.8276 || training accuracy 90.50% || lr [0.00025]||fl_score_train : 0.8885039682539684\n",
      "Epoch[3/5](600/1890) || training loss 0.8542 || training accuracy 89.25% || lr [0.00025]||fl_score_train : 0.8644219576719575\n",
      "Epoch[3/5](700/1890) || training loss 0.8281 || training accuracy 89.38% || lr [0.00025]||fl_score_train : 0.8775978835978836\n",
      "Epoch[3/5](800/1890) || training loss 0.8805 || training accuracy 85.25% || lr [0.00025]||fl_score_train : 0.8253948412698412\n",
      "Epoch[3/5](900/1890) || training loss 0.8133 || training accuracy 87.88% || lr [0.00025]||fl_score_train : 0.8553682539682538\n",
      "Epoch[3/5](1000/1890) || training loss 0.8076 || training accuracy 92.38% || lr [0.00025]||fl_score_train : 0.9058113756613756\n",
      "Epoch[3/5](1100/1890) || training loss 0.7876 || training accuracy 92.88% || lr [0.00025]||fl_score_train : 0.9156722222222221\n",
      "Epoch[3/5](1200/1890) || training loss 0.8027 || training accuracy 90.62% || lr [0.00025]||fl_score_train : 0.879692328042328\n",
      "Epoch[3/5](1300/1890) || training loss 0.8182 || training accuracy 92.88% || lr [0.00025]||fl_score_train : 0.906986507936508\n",
      "Epoch[3/5](1400/1890) || training loss 0.8457 || training accuracy 88.88% || lr [0.00025]||fl_score_train : 0.8683626984126985\n",
      "Epoch[3/5](1500/1890) || training loss 0.8474 || training accuracy 85.75% || lr [0.00025]||fl_score_train : 0.8404019841269842\n",
      "Epoch[3/5](1600/1890) || training loss 0.8812 || training accuracy 86.88% || lr [0.00025]||fl_score_train : 0.841871164021164\n",
      "Epoch[3/5](1700/1890) || training loss 0.8067 || training accuracy 90.62% || lr [0.00025]||fl_score_train : 0.8896936507936509\n",
      "Epoch[3/5](1800/1890) || training loss 0.8582 || training accuracy 88.25% || lr [0.00025]||fl_score_train : 0.857227380952381\n",
      "Calculating validation results...\n",
      "[Val] acc : 99.26%, loss:  0.6 || f1_score: 0.9883841129507089 ||best acc : 99.47%, best loss:  0.6\n",
      "Epoch[4/5](100/1890) || training loss 0.8812 || training accuracy 84.88% || lr [0.00025]||fl_score_train : 0.8270420634920634\n",
      "Epoch[4/5](200/1890) || training loss 0.8457 || training accuracy 86.00% || lr [0.00025]||fl_score_train : 0.8323611111111113\n",
      "Epoch[4/5](300/1890) || training loss 0.8867 || training accuracy 85.62% || lr [0.00025]||fl_score_train : 0.8267674603174604\n",
      "Epoch[4/5](400/1890) || training loss 0.843 || training accuracy 88.12% || lr [0.00025]||fl_score_train : 0.8525982382696666\n",
      "Epoch[4/5](500/1890) || training loss 0.7845 || training accuracy 94.00% || lr [0.00025]||fl_score_train : 0.9259679138321998\n",
      "Epoch[4/5](600/1890) || training loss 0.8653 || training accuracy 90.00% || lr [0.00025]||fl_score_train : 0.8719420634920635\n",
      "Epoch[4/5](700/1890) || training loss 0.8174 || training accuracy 91.88% || lr [0.00025]||fl_score_train : 0.8970563612313611\n",
      "Epoch[4/5](800/1890) || training loss 0.8427 || training accuracy 91.25% || lr [0.00025]||fl_score_train : 0.8966145502645502\n",
      "Epoch[4/5](900/1890) || training loss 0.8605 || training accuracy 86.25% || lr [0.00025]||fl_score_train : 0.8389023088023088\n",
      "Epoch[4/5](1000/1890) || training loss 0.8061 || training accuracy 89.25% || lr [0.00025]||fl_score_train : 0.8781396825396826\n",
      "Epoch[4/5](1100/1890) || training loss 0.8452 || training accuracy 89.12% || lr [0.00025]||fl_score_train : 0.8705436507936504\n",
      "Epoch[4/5](1200/1890) || training loss 0.8081 || training accuracy 90.38% || lr [0.00025]||fl_score_train : 0.889841774891775\n",
      "Epoch[4/5](1300/1890) || training loss 0.8431 || training accuracy 87.62% || lr [0.00025]||fl_score_train : 0.8565611111111109\n",
      "Epoch[4/5](1400/1890) || training loss 0.8318 || training accuracy 89.50% || lr [0.00025]||fl_score_train : 0.8722925925925925\n",
      "Epoch[4/5](1500/1890) || training loss 0.838 || training accuracy 92.00% || lr [0.00025]||fl_score_train : 0.8979095238095237\n",
      "Epoch[4/5](1600/1890) || training loss 0.8534 || training accuracy 87.00% || lr [0.00025]||fl_score_train : 0.8532317460317461\n",
      "Epoch[4/5](1700/1890) || training loss 0.8762 || training accuracy 90.00% || lr [0.00025]||fl_score_train : 0.8745119047619044\n",
      "Epoch[4/5](1800/1890) || training loss 0.8899 || training accuracy 85.12% || lr [0.00025]||fl_score_train : 0.815514826839827\n",
      "Calculating validation results...\n",
      "[Val] acc : 99.37%, loss:  0.6 || f1_score: 0.9889832178627103 ||best acc : 99.47%, best loss:  0.6\n"
     ]
    }
   ],
   "source": [
    "#cutmix training\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train loop\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    train_acc = 0 \n",
    "    train_f1 = 0\n",
    "    for idx, (inputs,targets) in enumerate(train_loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs,lam,target_a,target_b,cut = CutMix_two(inputs,targets,cutmix_prob=0.5)\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        if cut:\n",
    "            target_a = target_a.to(device)\n",
    "            target_b = target_b.to(device)\n",
    "            loss = criterion(outs, target_a) * lam + criterion(outs, target_b)* (1-lam)\n",
    "        else:\n",
    "            target_a = target_a.to(device)\n",
    "            loss = criterion(outs, target_a)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        loss_value += loss.item()\n",
    "        train_acc += accuracy_score(targets.cpu(),preds.cpu())\n",
    "        train_f1 += f1_score(targets.cpu(),preds.cpu(),average='macro')\n",
    "\n",
    "        if (idx + 1) % train_log_interval == 0:\n",
    "            train_loss = loss_value / train_log_interval\n",
    "            avg_train_acc = train_acc / train_log_interval\n",
    "            avg_train_f1 = train_f1 / train_log_interval\n",
    "            \n",
    "            current_lr = scheduler.get_last_lr()\n",
    "\n",
    "            print(\n",
    "                f\"Epoch[{epoch}/{num_epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                f\"training loss {train_loss:4.4} || training accuracy {avg_train_acc:4.2%} || lr {current_lr}||\"\n",
    "                \"fl_score_train : {}\".format(avg_train_f1)\n",
    "            )\n",
    "\n",
    "            loss_value = 0\n",
    "            train_acc = 0\n",
    "            train_f1 = 0\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # val loop\n",
    "    with torch.no_grad():\n",
    "        print(\"Calculating validation results...\")\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_f1 = 0\n",
    "        val_acc = 0\n",
    "        for idx,(inputs,labels) in enumerate(val_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "            \n",
    "            val_acc += accuracy_score(labels.cpu(),preds.cpu())\n",
    "            val_f1 += f1_score(labels.cpu(),preds.cpu(),average='macro')\n",
    "            \n",
    "            loss_item = criterion(outs, labels).item()\n",
    "            val_loss_items.append(loss_item)\n",
    "\n",
    "        val_loss = np.sum(val_loss_items) / len(val_loader)\n",
    "        avg_val_acc = val_acc / (idx+1)\n",
    "        avg_val_f1 = val_f1 / (idx+1)\n",
    "        \n",
    "        \n",
    "        # Callback1: validation accuracy가 향상될수록 모델을 저장합니다.\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "        if avg_val_acc > best_val_acc:\n",
    "            print(\"New best model for val accuracy! saving the model..\")\n",
    "            torch.save(model.state_dict(), f\"result_{epoch:03}_accuracy_{avg_val_acc:4.2%}.ckpt\")\n",
    "            best_val_acc = avg_val_acc\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        # Callback2: patience 횟수 동안 성능 향상이 없을 경우 학습을 종료시킵니다.\n",
    "        if counter > patience:\n",
    "            print(\"Early Stopping...\")\n",
    "            break\n",
    "        \n",
    "        \n",
    "        print(\n",
    "            f\"[Val] acc : {avg_val_acc:4.2%}, loss: {val_loss:4.2} || f1_score: {avg_val_f1} ||\"\n",
    "            f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/10](100/473) || training loss 2.461 || training accuracy 20.97% || lr [0.01]||fl_score_train : 0.032290895432331636\n",
      "Epoch[0/10](200/473) || training loss 2.41 || training accuracy 22.00% || lr [0.01]||fl_score_train : 0.03564169476281975\n",
      "Epoch[0/10](300/473) || training loss 2.428 || training accuracy 21.88% || lr [0.01]||fl_score_train : 0.03407106069073554\n",
      "Epoch[0/10](400/473) || training loss 2.427 || training accuracy 22.00% || lr [0.01]||fl_score_train : 0.0344657374821741\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 21.11%, loss:  2.4 || f1_score: 0.03298499483179209 ||best acc : 21.11%, best loss:  2.4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-ffe5a6d20f95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#cutmix training 2\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train loop\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    train_acc = 0 \n",
    "    train_f1 = 0\n",
    "    for idx, (inputs,targets) in enumerate(train_loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs,labels = CutMix(inputs,targets,cutmix_prob=0.3)\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        loss = criterion(outs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        loss_value += loss.item()\n",
    "        train_acc += accuracy_score(targets.cpu(),preds.cpu())\n",
    "        train_f1 += f1_score(targets.cpu(),preds.cpu(),average='macro')\n",
    "\n",
    "        if (idx + 1) % train_log_interval == 0:\n",
    "            train_loss = loss_value / train_log_interval\n",
    "            avg_train_acc = train_acc / train_log_interval\n",
    "            avg_train_f1 = train_f1 / train_log_interval\n",
    "            \n",
    "            current_lr = scheduler.get_last_lr()\n",
    "\n",
    "            print(\n",
    "                f\"Epoch[{epoch}/{num_epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                f\"training loss {train_loss:4.4} || training accuracy {avg_train_acc:4.2%} || lr {current_lr}||\"\n",
    "                \"fl_score_train : {}\".format(avg_train_f1)\n",
    "            )\n",
    "\n",
    "            loss_value = 0\n",
    "            train_acc = 0\n",
    "            train_f1 = 0\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # val loop\n",
    "    with torch.no_grad():\n",
    "        print(\"Calculating validation results...\")\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_f1 = 0\n",
    "        val_acc = 0\n",
    "        for idx,(inputs,labels) in enumerate(val_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "            \n",
    "            val_acc += accuracy_score(labels.cpu(),preds.cpu())\n",
    "            val_f1 += f1_score(labels.cpu(),preds.cpu(),average='macro')\n",
    "            \n",
    "            loss_item = criterion(outs, labels).item()\n",
    "            val_loss_items.append(loss_item)\n",
    "\n",
    "        val_loss = np.sum(val_loss_items) / len(val_loader)\n",
    "        avg_val_acc = val_acc / (idx+1)\n",
    "        avg_val_f1 = val_f1 / (idx+1)\n",
    "        \n",
    "        \n",
    "        # Callback1: validation accuracy가 향상될수록 모델을 저장합니다.\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "        if avg_val_acc > best_val_acc:\n",
    "            print(\"New best model for val accuracy! saving the model..\")\n",
    "            torch.save(model.state_dict(), f\"result_{epoch:03}_accuracy_{avg_val_acc:4.2%}.ckpt\")\n",
    "            best_val_acc = avg_val_acc\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        # Callback2: patience 횟수 동안 성능 향상이 없을 경우 학습을 종료시킵니다.\n",
    "        if counter > patience:\n",
    "            print(\"Early Stopping...\")\n",
    "            break\n",
    "        \n",
    "        \n",
    "        print(\n",
    "            f\"[Val] acc : {avg_val_acc:4.2%}, loss: {val_loss:4.2} || f1_score: {avg_val_f1} ||\"\n",
    "            f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/10](100/472) || training loss 1.387 || training accuracy 70.44% || lr [0.001]||fl_score_train : 0.5170381672729036\n",
      "Epoch[0/10](200/472) || training loss 1.01 || training accuracy 82.91% || lr [0.001]||fl_score_train : 0.6796844283469174\n",
      "Epoch[0/10](300/472) || training loss 0.9222 || training accuracy 87.34% || lr [0.001]||fl_score_train : 0.7652154375596248\n",
      "Epoch[0/10](400/472) || training loss 0.9119 || training accuracy 87.31% || lr [0.001]||fl_score_train : 0.7536396747027149\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 88.29%, loss: 0.87 || f1_score: 0.7711771300654587 ||best acc : 88.29%, best loss: 0.87\n",
      "Epoch[1/10](100/472) || training loss 0.7735 || training accuracy 93.00% || lr [0.0005]||fl_score_train : 0.8579344988942027\n",
      "Epoch[1/10](200/472) || training loss 0.7107 || training accuracy 95.31% || lr [0.0005]||fl_score_train : 0.8993191227049467\n",
      "Epoch[1/10](300/472) || training loss 0.6773 || training accuracy 96.47% || lr [0.0005]||fl_score_train : 0.9231685740103843\n",
      "Epoch[1/10](400/472) || training loss 0.6672 || training accuracy 97.00% || lr [0.0005]||fl_score_train : 0.9345872413999138\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 97.30%, loss: 0.66 || f1_score: 0.9500963319259952 ||best acc : 97.30%, best loss: 0.66\n",
      "Epoch[2/10](100/472) || training loss 0.6354 || training accuracy 98.22% || lr [0.0]||fl_score_train : 0.9636028838789145\n",
      "Epoch[2/10](200/472) || training loss 0.6338 || training accuracy 98.34% || lr [0.0]||fl_score_train : 0.9567309496867428\n",
      "Epoch[2/10](300/472) || training loss 0.624 || training accuracy 98.84% || lr [0.0]||fl_score_train : 0.9767425337991902\n",
      "Epoch[2/10](400/472) || training loss 0.6291 || training accuracy 98.28% || lr [0.0]||fl_score_train : 0.9650789828374698\n",
      "Calculating validation results...\n",
      "[Val] acc : 97.25%, loss: 0.66 || f1_score: 0.9486398809879888 ||best acc : 97.30%, best loss: 0.66\n",
      "Epoch[3/10](100/472) || training loss 0.6438 || training accuracy 97.56% || lr [0.0004999999999999999]||fl_score_train : 0.9459272552701233\n",
      "Epoch[3/10](200/472) || training loss 0.6517 || training accuracy 97.84% || lr [0.0004999999999999999]||fl_score_train : 0.9483713963959061\n",
      "Epoch[3/10](300/472) || training loss 0.642 || training accuracy 97.94% || lr [0.0004999999999999999]||fl_score_train : 0.9548878958054725\n",
      "Epoch[3/10](400/472) || training loss 0.6527 || training accuracy 97.56% || lr [0.0004999999999999999]||fl_score_train : 0.9519970168612155\n",
      "Calculating validation results...\n",
      "[Val] acc : 96.32%, loss: 0.68 || f1_score: 0.9322945196809183 ||best acc : 97.30%, best loss: 0.66\n",
      "Epoch[4/10](100/472) || training loss 0.7593 || training accuracy 93.47% || lr [0.001]||fl_score_train : 0.8835267531836004\n",
      "Epoch[4/10](200/472) || training loss 0.7569 || training accuracy 93.38% || lr [0.001]||fl_score_train : 0.8619332370771359\n",
      "Epoch[4/10](300/472) || training loss 0.7281 || training accuracy 94.44% || lr [0.001]||fl_score_train : 0.8950343519890366\n",
      "Epoch[4/10](400/472) || training loss 0.7417 || training accuracy 93.81% || lr [0.001]||fl_score_train : 0.8869571379714409\n",
      "Calculating validation results...\n",
      "[Val] acc : 92.21%, loss: 0.79 || f1_score: 0.851807471212077 ||best acc : 97.30%, best loss: 0.66\n",
      "Epoch[5/10](100/472) || training loss 0.6469 || training accuracy 97.75% || lr [0.0005000000000000001]||fl_score_train : 0.9507535704672287\n",
      "Epoch[5/10](200/472) || training loss 0.6194 || training accuracy 98.66% || lr [0.0005000000000000001]||fl_score_train : 0.9672928063829643\n",
      "Epoch[5/10](300/472) || training loss 0.6012 || training accuracy 99.50% || lr [0.0005000000000000001]||fl_score_train : 0.9897414716711084\n",
      "Epoch[5/10](400/472) || training loss 0.6053 || training accuracy 99.44% || lr [0.0005000000000000001]||fl_score_train : 0.9871629482774993\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 98.49%, loss: 0.62 || f1_score: 0.9693738707221156 ||best acc : 98.49%, best loss: 0.62\n",
      "Epoch[6/10](100/472) || training loss 0.5923 || training accuracy 99.78% || lr [0.0]||fl_score_train : 0.9955411255411255\n",
      "Epoch[6/10](200/472) || training loss 0.5927 || training accuracy 99.72% || lr [0.0]||fl_score_train : 0.992060958794292\n",
      "Epoch[6/10](300/472) || training loss 0.5898 || training accuracy 99.81% || lr [0.0]||fl_score_train : 0.9943948375511128\n",
      "Epoch[6/10](400/472) || training loss 0.5937 || training accuracy 99.66% || lr [0.0]||fl_score_train : 0.9922346912346911\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 98.57%, loss: 0.62 || f1_score: 0.9703665764084326 ||best acc : 98.57%, best loss: 0.62\n",
      "Epoch[7/10](100/472) || training loss 0.5898 || training accuracy 99.78% || lr [0.0004999999999999999]||fl_score_train : 0.9929577829577828\n",
      "Epoch[7/10](200/472) || training loss 0.5937 || training accuracy 99.59% || lr [0.0004999999999999999]||fl_score_train : 0.9894770650579261\n",
      "Epoch[7/10](300/472) || training loss 0.5878 || training accuracy 99.84% || lr [0.0004999999999999999]||fl_score_train : 0.9964053489744455\n",
      "Epoch[7/10](400/472) || training loss 0.5918 || training accuracy 99.72% || lr [0.0004999999999999999]||fl_score_train : 0.9927591519591519\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 98.89%, loss: 0.61 || f1_score: 0.9788550573336166 ||best acc : 98.89%, best loss: 0.61\n",
      "Epoch[8/10](100/472) || training loss 0.6398 || training accuracy 97.97% || lr [0.0010000000000000002]||fl_score_train : 0.9486096202596562\n",
      "Epoch[8/10](200/472) || training loss 0.7832 || training accuracy 92.31% || lr [0.0010000000000000002]||fl_score_train : 0.862354065272708\n",
      "Epoch[8/10](300/472) || training loss 0.7885 || training accuracy 92.38% || lr [0.0010000000000000002]||fl_score_train : 0.8547245312636711\n",
      "Epoch[8/10](400/472) || training loss 0.7396 || training accuracy 94.12% || lr [0.0010000000000000002]||fl_score_train : 0.8833071656687207\n",
      "Calculating validation results...\n",
      "[Val] acc : 93.54%, loss: 0.75 || f1_score: 0.8897996731591593 ||best acc : 98.89%, best loss: 0.61\n",
      "Epoch[9/10](100/472) || training loss 0.638 || training accuracy 98.28% || lr [0.0005000000000000003]||fl_score_train : 0.9669664651626778\n",
      "Epoch[9/10](200/472) || training loss 0.6055 || training accuracy 99.53% || lr [0.0005000000000000003]||fl_score_train : 0.988646011504835\n",
      "Epoch[9/10](300/472) || training loss 0.6002 || training accuracy 99.50% || lr [0.0005000000000000003]||fl_score_train : 0.9910866452610049\n",
      "Epoch[9/10](400/472) || training loss 0.5981 || training accuracy 99.59% || lr [0.0005000000000000003]||fl_score_train : 0.9897130596676048\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 98.94%, loss: 0.61 || f1_score: 0.9818564077438637 ||best acc : 98.94%, best loss: 0.61\n"
     ]
    }
   ],
   "source": [
    "#basic training\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train loop\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    train_acc = 0 \n",
    "    train_f1 = 0\n",
    "    for idx, (inputs,labels) in enumerate(train_loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        loss = criterion(outs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        loss_value += loss.item()\n",
    "        train_acc += accuracy_score(labels.cpu(),preds.cpu())\n",
    "        train_f1 += f1_score(labels.cpu(),preds.cpu(),average='macro')\n",
    "\n",
    "        if (idx + 1) % train_log_interval == 0:\n",
    "            train_loss = loss_value / train_log_interval\n",
    "            avg_train_acc = train_acc / train_log_interval\n",
    "            avg_train_f1 = train_f1 / train_log_interval\n",
    "            \n",
    "            current_lr = scheduler.get_last_lr()\n",
    "    \n",
    "            print(\n",
    "                f\"Epoch[{epoch}/{num_epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                f\"training loss {train_loss:4.4} || training accuracy {avg_train_acc:4.2%} || lr {current_lr}||\"\n",
    "                \"fl_score_train : {}\".format(avg_train_f1)\n",
    "            )\n",
    "\n",
    "            loss_value = 0\n",
    "            train_acc = 0\n",
    "            train_f1 = 0\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # val loop\n",
    "    with torch.no_grad():\n",
    "        print(\"Calculating validation results...\")\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_f1 = 0\n",
    "        val_acc = 0\n",
    "        for idx,(inputs,labels) in enumerate(val_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "            \n",
    "            val_acc += accuracy_score(labels.cpu(),preds.cpu())\n",
    "            val_f1 += f1_score(labels.cpu(),preds.cpu(),average='macro')\n",
    "            \n",
    "            loss_item = criterion(outs, labels).item()\n",
    "            val_loss_items.append(loss_item)\n",
    "\n",
    "        val_loss = np.sum(val_loss_items) / len(val_loader)\n",
    "        avg_val_acc = val_acc / (idx+1)\n",
    "        avg_val_f1 = val_f1 / (idx+1)\n",
    "        \n",
    "        \n",
    "        # Callback1: validation accuracy가 향상될수록 모델을 저장합니다.\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "        \n",
    "        if avg_val_acc > best_val_acc:\n",
    "            print(\"New best model for val accuracy! saving the model..\")\n",
    "            torch.save(model.state_dict(), f\"result_{epoch:03}_accuracy_{avg_val_acc:4.2%}.ckpt\")\n",
    "            best_val_acc = avg_val_acc\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        # Callback2: patience 횟수 동안 성능 향상이 없을 경우 학습을 종료시킵니다.\n",
    "        if counter > patience:\n",
    "            print(\"Early Stopping...\")\n",
    "            break\n",
    "        \n",
    "        \n",
    "        print(\n",
    "            f\"[Val] acc : {avg_val_acc:4.2%}, loss: {val_loss:4.2} || f1_score: {avg_val_f1} ||\"\n",
    "            f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
